{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf731a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/R/lib:/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server\n",
      "/usr/lib/R/lib:/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['LD_LIBRARY_PATH'])\n",
    "!echo $LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e9af9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scottweichenthal/Dropbox/IMAGINE Project/MSSI_Project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:14:12.864559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.864909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.865211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.865511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.892144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.892457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.892696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.892935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.893170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.893399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.893626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:14:12.893854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# for figures\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import seaborn as sns\n",
    "\n",
    "# for the Grad-CAMs\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#Working Directory on A4 Computer (GoPro and V2 data are on the A4 Computer)\n",
    "\n",
    "files = os.listdir()\n",
    "    \n",
    "os.chdir(\"/home/scottweichenthal/Dropbox/IMAGINE Project/MSSI_Project/\")\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "\n",
    "#This code allows GPU memory allocation to grow as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d47e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n",
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "#  Prints the Tensorflow, Keras versions, and number of GPUs\n",
    "print(tf.__version__)\n",
    "print(K.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0557a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "#Which Python Version\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f449af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata for compiled data you want to use for CNN model development\n",
    "#This version has GoPro in trn and val sets\n",
    "#metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_15012024.csv\", low_memory=False)\n",
    "\n",
    "#This version has GoPro data only in trn set (as opposed to random split between trn,val,tst)\n",
    "# metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04042024.csv\", low_memory=False)\n",
    "# Train: 100% GoPro + 80% Imagine V2\n",
    "# Val: 10% Imagine V2\n",
    "# Tst: 10% Imagine V2\n",
    "# External Test: 100% Imagine V3\n",
    "\n",
    "\n",
    "#This compiled file incorporate all existing data with GoPro in training set only. Rishabh Please use this file!\n",
    "\n",
    "metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04252024.csv\", low_memory=False)\n",
    "# Train: 100% GoPro + 80% Imagine V2 and V3\n",
    "# Val: 10% Imagine V2 and V3\n",
    "# Tst: 10% Imagine V2 and V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69309e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data\n",
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679ebd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "image_path\n",
      "audio_path\n",
      "ln_ufp_num_10s_ma_image_label_raw\n",
      "ln_ufp_num_10s_ma_spec_label_raw\n",
      "ln_ufp_size_10s_ma_image_label_raw\n",
      "ln_ufp_size_10s_ma_spec_label_raw\n",
      "ln_noise_10s_ma_image_label_raw\n",
      "ln_noise_10s_ma_spec_label_raw\n",
      "ufp_num_10s_ma_image_label_raw\n",
      "ufp_num_10s_ma_spec_label_raw\n",
      "ufp_size_10s_ma_image_label_raw\n",
      "ufp_size_10s_ma_spec_label_raw\n",
      "noise_10s_ma_image_label_raw\n",
      "noise_10s_ma_spec_label_raw\n",
      "temp_airp\n",
      "wspd_airp\n",
      "year\n",
      "city\n",
      "pm25\n",
      "file_exists\n",
      "hardware\n",
      "site_id\n",
      "device_id\n",
      "file\n",
      "noise_10s_ma_spec_label_quartile\n",
      "noise_10s_ma_image_label_quartile\n",
      "ufp_num_10s_ma_spec_label_quartile\n",
      "ufp_num_10s_ma_image_label_quartile\n",
      "ufp_size_10s_ma_spec_label_quartile\n",
      "ufp_size_10s_ma_image_label_quartile\n",
      "image_extension\n",
      "audio_extension\n",
      "image_name\n",
      "audio_name\n",
      "pair_pm25\n",
      "set_V3ext\n",
      "set\n",
      "vsby_nm\n"
     ]
    }
   ],
   "source": [
    "#Look at variable names\n",
    "for col in metadata.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d534aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trn    345680\n",
       "val     22407\n",
       "tst     22223\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much data in trn, val, tst sets for metadata_random_split\n",
    "\n",
    "metadata.set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121002b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_num_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_image_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_spec_label_raw</th>\n",
       "      <th>ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>ufp_num_10s_ma_spec_label_raw</th>\n",
       "      <th>ufp_size_10s_ma_image_label_raw</th>\n",
       "      <th>ufp_size_10s_ma_spec_label_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>pm25</th>\n",
       "      <th>device_id</th>\n",
       "      <th>noise_10s_ma_spec_label_quartile</th>\n",
       "      <th>noise_10s_ma_image_label_quartile</th>\n",
       "      <th>ufp_num_10s_ma_spec_label_quartile</th>\n",
       "      <th>ufp_num_10s_ma_image_label_quartile</th>\n",
       "      <th>ufp_size_10s_ma_spec_label_quartile</th>\n",
       "      <th>ufp_size_10s_ma_image_label_quartile</th>\n",
       "      <th>pair_pm25</th>\n",
       "      <th>vsby_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>3.903100e+05</td>\n",
       "      <td>3.903100e+05</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>359005.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>390039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.301744</td>\n",
       "      <td>9.302244</td>\n",
       "      <td>3.513263</td>\n",
       "      <td>3.513208</td>\n",
       "      <td>4.115388</td>\n",
       "      <td>4.115988</td>\n",
       "      <td>1.512980e+04</td>\n",
       "      <td>1.513813e+04</td>\n",
       "      <td>36.045195</td>\n",
       "      <td>36.040962</td>\n",
       "      <td>...</td>\n",
       "      <td>6.629045</td>\n",
       "      <td>28.877045</td>\n",
       "      <td>1.446513</td>\n",
       "      <td>1.429632</td>\n",
       "      <td>1.481508</td>\n",
       "      <td>1.479643</td>\n",
       "      <td>1.554374</td>\n",
       "      <td>1.555392</td>\n",
       "      <td>6.911002</td>\n",
       "      <td>21.609274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.779956</td>\n",
       "      <td>0.779607</td>\n",
       "      <td>0.385172</td>\n",
       "      <td>0.384935</td>\n",
       "      <td>0.118462</td>\n",
       "      <td>0.119192</td>\n",
       "      <td>2.221654e+04</td>\n",
       "      <td>2.205105e+04</td>\n",
       "      <td>13.837587</td>\n",
       "      <td>13.835993</td>\n",
       "      <td>...</td>\n",
       "      <td>3.997787</td>\n",
       "      <td>5.682456</td>\n",
       "      <td>1.124708</td>\n",
       "      <td>1.114186</td>\n",
       "      <td>1.118695</td>\n",
       "      <td>1.118875</td>\n",
       "      <td>1.129159</td>\n",
       "      <td>1.129161</td>\n",
       "      <td>6.502780</td>\n",
       "      <td>8.166993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.895912</td>\n",
       "      <td>2.906901</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.598134</td>\n",
       "      <td>3.598134</td>\n",
       "      <td>1.810000e+01</td>\n",
       "      <td>1.830000e+01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666429</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.812397</td>\n",
       "      <td>8.812073</td>\n",
       "      <td>3.255401</td>\n",
       "      <td>3.255015</td>\n",
       "      <td>4.041471</td>\n",
       "      <td>4.040768</td>\n",
       "      <td>6.717000e+03</td>\n",
       "      <td>6.714825e+03</td>\n",
       "      <td>25.930000</td>\n",
       "      <td>25.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.626583</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.214500</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.317678</td>\n",
       "      <td>9.317849</td>\n",
       "      <td>3.564732</td>\n",
       "      <td>3.563883</td>\n",
       "      <td>4.121798</td>\n",
       "      <td>4.122608</td>\n",
       "      <td>1.113310e+04</td>\n",
       "      <td>1.113500e+04</td>\n",
       "      <td>35.330000</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.105735</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.799500</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.831824</td>\n",
       "      <td>9.832088</td>\n",
       "      <td>3.790985</td>\n",
       "      <td>3.790985</td>\n",
       "      <td>4.197052</td>\n",
       "      <td>4.199455</td>\n",
       "      <td>1.861688e+04</td>\n",
       "      <td>1.862180e+04</td>\n",
       "      <td>44.300000</td>\n",
       "      <td>44.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.358984</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.310000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.074470</td>\n",
       "      <td>14.446425</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>4.618876</td>\n",
       "      <td>4.627910</td>\n",
       "      <td>3.521756e+06</td>\n",
       "      <td>1.879329e+06</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.562680</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.094250</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ln_ufp_num_10s_ma_image_label_raw  ln_ufp_num_10s_ma_spec_label_raw  \\\n",
       "count                      390310.000000                     390310.000000   \n",
       "mean                            9.301744                          9.302244   \n",
       "std                             0.779956                          0.779607   \n",
       "min                             2.895912                          2.906901   \n",
       "25%                             8.812397                          8.812073   \n",
       "50%                             9.317678                          9.317849   \n",
       "75%                             9.831824                          9.832088   \n",
       "max                            15.074470                         14.446425   \n",
       "\n",
       "       ln_ufp_size_10s_ma_image_label_raw  ln_ufp_size_10s_ma_spec_label_raw  \\\n",
       "count                       390310.000000                      390310.000000   \n",
       "mean                             3.513263                           3.513208   \n",
       "std                              0.385172                           0.384935   \n",
       "min                              2.302585                           2.302585   \n",
       "25%                              3.255401                           3.255015   \n",
       "50%                              3.564732                           3.563883   \n",
       "75%                              3.790985                           3.790985   \n",
       "max                              5.703782                           5.703782   \n",
       "\n",
       "       ln_noise_10s_ma_image_label_raw  ln_noise_10s_ma_spec_label_raw  \\\n",
       "count                    390310.000000                   390310.000000   \n",
       "mean                          4.115388                        4.115988   \n",
       "std                           0.118462                        0.119192   \n",
       "min                           3.598134                        3.598134   \n",
       "25%                           4.041471                        4.040768   \n",
       "50%                           4.121798                        4.122608   \n",
       "75%                           4.197052                        4.199455   \n",
       "max                           4.618876                        4.627910   \n",
       "\n",
       "       ufp_num_10s_ma_image_label_raw  ufp_num_10s_ma_spec_label_raw  \\\n",
       "count                    3.903100e+05                   3.903100e+05   \n",
       "mean                     1.512980e+04                   1.513813e+04   \n",
       "std                      2.221654e+04                   2.205105e+04   \n",
       "min                      1.810000e+01                   1.830000e+01   \n",
       "25%                      6.717000e+03                   6.714825e+03   \n",
       "50%                      1.113310e+04                   1.113500e+04   \n",
       "75%                      1.861688e+04                   1.862180e+04   \n",
       "max                      3.521756e+06                   1.879329e+06   \n",
       "\n",
       "       ufp_size_10s_ma_image_label_raw  ufp_size_10s_ma_spec_label_raw  ...  \\\n",
       "count                    390310.000000                   390310.000000  ...   \n",
       "mean                         36.045195                       36.040962  ...   \n",
       "std                          13.837587                       13.835993  ...   \n",
       "min                          10.000000                       10.000000  ...   \n",
       "25%                          25.930000                       25.920000  ...   \n",
       "50%                          35.330000                       35.300000  ...   \n",
       "75%                          44.300000                       44.300000  ...   \n",
       "max                         300.000000                      300.000000  ...   \n",
       "\n",
       "                pm25      device_id  noise_10s_ma_spec_label_quartile  \\\n",
       "count  359005.000000  223147.000000                     223147.000000   \n",
       "mean        6.629045      28.877045                          1.446513   \n",
       "std         3.997787       5.682456                          1.124708   \n",
       "min         0.666429      18.000000                          0.000000   \n",
       "25%         3.626583      28.000000                          0.000000   \n",
       "50%         6.105735      29.000000                          1.000000   \n",
       "75%         8.358984      30.000000                          2.000000   \n",
       "max        46.562680      41.000000                          3.000000   \n",
       "\n",
       "       noise_10s_ma_image_label_quartile  ufp_num_10s_ma_spec_label_quartile  \\\n",
       "count                      223147.000000                       223147.000000   \n",
       "mean                            1.429632                            1.481508   \n",
       "std                             1.114186                            1.118695   \n",
       "min                             0.000000                            0.000000   \n",
       "25%                             0.000000                            0.000000   \n",
       "50%                             1.000000                            1.000000   \n",
       "75%                             2.000000                            2.000000   \n",
       "max                             3.000000                            3.000000   \n",
       "\n",
       "       ufp_num_10s_ma_image_label_quartile  \\\n",
       "count                        223147.000000   \n",
       "mean                              1.479643   \n",
       "std                               1.118875   \n",
       "min                               0.000000   \n",
       "25%                               0.000000   \n",
       "50%                               1.000000   \n",
       "75%                               2.000000   \n",
       "max                               3.000000   \n",
       "\n",
       "       ufp_size_10s_ma_spec_label_quartile  \\\n",
       "count                        223147.000000   \n",
       "mean                              1.554374   \n",
       "std                               1.129159   \n",
       "min                               0.000000   \n",
       "25%                               1.000000   \n",
       "50%                               2.000000   \n",
       "75%                               3.000000   \n",
       "max                               3.000000   \n",
       "\n",
       "       ufp_size_10s_ma_image_label_quartile      pair_pm25        vsby_nm  \n",
       "count                         223147.000000  223147.000000  390039.000000  \n",
       "mean                               1.555392       6.911002      21.609274  \n",
       "std                                1.129161       6.502780       8.166993  \n",
       "min                                0.000000       0.356000       0.380000  \n",
       "25%                                1.000000       3.214500      15.000000  \n",
       "50%                                2.000000       4.799500      15.000000  \n",
       "75%                                3.000000       8.310000      30.000000  \n",
       "max                                3.000000      80.094250      60.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6eaefca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What input are you using: images, or spectrograms? images\n"
     ]
    }
   ],
   "source": [
    "#Select input file type (this tells python where to look for the file paths)\n",
    "file = input(\"What input are you using: images, or spectrograms? \")\n",
    "\n",
    "if file == 'images':\n",
    "    file = 'image_path'\n",
    "else:\n",
    "  if file == 'spectrograms':\n",
    "      file = 'audio_path'\n",
    "  else:\n",
    "    print('!!!TYPO in input_data name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e16d5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Initial Learning Rate\n",
    "initial_learning_rate = 1e-4\n",
    "meta_data_name = \"gp_v2_v3_Training_Only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02a203d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What architecture do you want to use: Xception_linear_Nadam, ResNet50_linear_Nadam ?ResNet50_linear_Nadam\n"
     ]
    }
   ],
   "source": [
    "architecture = input(\"What architecture do you want to use: Xception_linear_Nadam, ResNet50_linear_Nadam ?\")\n",
    "if architecture == 'Xception_linear_Nadam':\n",
    "    architecture_preprocessing = K.applications.xception.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.Xception(include_top=False, weights = \"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units= 1, activation='linear')(model_output) \n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "            loss = 'mse',\n",
    "            metrics = ['mae']\n",
    "        )\n",
    "        return model\n",
    "                    \n",
    "elif architecture == 'ResNet50_linear_Nadam':\n",
    "    architecture_preprocessing = K.applications.resnet50.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ResNet50(include_top=False, weights= \"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units= 1, activation='linear')(model_output) \n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "            loss = 'mse',\n",
    "            metrics = ['mae']\n",
    "        )\n",
    "        return model\n",
    "                      \n",
    "else:\n",
    "    print('!!!TYPO in architecture name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f002aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scottweichenthal/Dropbox/IMAGINE Project/MSSI_Project\n",
      "What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ?ln_noise_10s_ma_image_label_raw\n",
      "Found 345680 validated image filenames.\n",
      "Found 22407 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Select Exposure to be modelled\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "target = input(\"What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ?\")                  \n",
    "\n",
    "if target == 'ln_noise_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "\n",
    "\n",
    "elif target == 'ln_noise_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    \n",
    "elif target == 'ln_ufp_num_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    \n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "\n",
    "\n",
    "elif target == 'ln_ufp_num_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    " \n",
    "    \n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "\n",
    "elif target == 'ln_ufp_size_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "\n",
    "else:\n",
    "    print('!!!TYPO in exposure name') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:35:05.360341: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 17:35:05.646613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.646879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.647109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.647338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.647570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.647793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.648012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.648231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.648450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.648670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.648891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:05.649110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.696934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.697225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.697473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.697717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.697951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.698182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.698407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.698655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.698886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.699117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4394 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-05-13 17:35:06.699414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.699624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 4522 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-05-13 17:35:06.699839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.700046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 4522 MB memory:  -> device: 2, name: NVIDIA RTX A4000, pci bus id: 0000:4b:00.0, compute capability: 8.6\n",
      "2024-05-13 17:35:06.700262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-13 17:35:06.700470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 4542 MB memory:  -> device: 3, name: NVIDIA RTX A4000, pci bus id: 0000:4c:00.0, compute capability: 8.6\n",
      "2024-05-13 17:35:10.383152: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_15367\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:36:17.834012: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-05-13 17:36:18.658713: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-05-13 17:36:19.754882: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-05-13 17:36:19.770720: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-05-13 17:36:22.901021: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.901065: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.904431: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.904476: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.915492: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.915524: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.918870: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.918905: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.920930: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_2_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.920981: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_2_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-05-13 17:36:22.926501: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2889/5402 [===============>..............] - ETA: 36:40 - loss: 0.0445 - mae: 0.1390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 18:18:33.751894: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-05-13 18:18:33.844893: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-05-13 18:18:33.847376: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-05-13 18:18:33.847416: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4293/5402 [======================>.......] - ETA: 16:10 - loss: 0.0332 - mae: 0.1194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3079/5402 [================>.............] - ETA: 33:56 - loss: 0.0069 - mae: 0.0656"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model = get_compiled_model()\n",
    "    \n",
    "\n",
    "#Fit Model\n",
    "model.fit(train_generator,\n",
    "          validation_data=validate_generator,\n",
    "          epochs=10, \n",
    "          steps_per_epoch=int(np.ceil(train_generator.samples/train_generator.batch_size)),\n",
    "          validation_steps=int(np.ceil(validate_generator.samples/validate_generator.batch_size)),\n",
    "          callbacks=[csv_logger, \n",
    "                     reduce_lr_on_plateau, \n",
    "                     model_checkpoint] \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4502660a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model_development/logs/ln_noise_10s_ma_spec_label_raw,ResNet50_linear_Nadam,image_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34313/2791530844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Identify Best Epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./model_development/logs/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmeta_data_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_Combined_IMAGINE_v2_GoPro.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model_development/logs/ln_noise_10s_ma_spec_label_raw,ResNet50_linear_Nadam,image_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.csv'"
     ]
    }
   ],
   "source": [
    "#Identify Best Epoch\n",
    "res = pd.read_csv(filepath_or_buffer='./model_development/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_v2_GoPro.csv')\n",
    "res = res.sort_values('val_loss', ascending=True).reset_index(drop=True)\n",
    "# print(res)\n",
    "best_epoch = res.epoch[0]\n",
    "print(res.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Generate Predictions for compiled data, add them to dataframe, save new dataframe #####\n",
    "\n",
    "#Load Metadata\n",
    "#metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_15012024.csv\", low_memory=False)\n",
    "\n",
    "#This version has GoPro data only in trn set (as opposed to random split between trn,val,tst)\n",
    "#metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04042024.csv\", low_memory=False)\n",
    "metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04042024.csv\", low_memory=False)\n",
    "\n",
    "# check to see if each image file exists and remove rows from the results dataframe for which image files don't exist.\n",
    "metadata['file_exists'] = metadata.apply(lambda row: os.path.isfile(row.image_path), axis = 1)\n",
    "\n",
    "#Remove missing files from metadata to avoid errors in adding predictions to dataframe\n",
    "metadata = metadata.loc[metadata['file_exists'] == True]\n",
    "metadata.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Predictions and Add to Database\n",
    "\n",
    "#Define Preprocessing functions\n",
    "architecture_preprocessing_resnet50 = K.applications.resnet50.preprocess_input\n",
    "architecture_preprocessing_xception = K.applications.xception.preprocess_input\n",
    "\n",
    "\n",
    "#Define Test Generators\n",
    "generator_tst_resnet50 = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing_resnet50, \n",
    "                                                     horizontal_flip=False,\n",
    "                                                     vertical_flip = False)\n",
    "\n",
    "generator_tst_xception = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing_xception, \n",
    "                                                     horizontal_flip=False,\n",
    "                                                     vertical_flip = False)\n",
    "\n",
    "test_generator_resnet50_audio = generator_tst_resnet50.flow_from_dataframe(dataframe=metadata[['audio_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'audio_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "test_generator_resnet50_image = generator_tst_resnet50.flow_from_dataframe(dataframe=metadata[['image_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'image_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "test_generator_xception_audio = generator_tst_xception.flow_from_dataframe(dataframe=metadata[['audio_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'audio_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "test_generator_xception_image = generator_tst_xception.flow_from_dataframe(dataframe=metadata[['image_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'image_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "                                                                       \n",
    "######### - Generate Predictions for Best CNN Models - ##############\n",
    "\n",
    "\n",
    "\n",
    "#Best model for log(ufp_num) based on images:  ln_ufp_num, image, ResNet50, raw\n",
    "ln_ufp_num_ResNet50_image_raw_model = load_model('model_development/models/ln_ufp_num_10s_ma_image_label_raw,ResNet50_linear_Nadam,image_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_ufp_num_ResNet50_image_raw_prediction'] = ln_ufp_num_ResNet50_image_raw_model.predict(x=test_generator_resnet50_image, \n",
    "                                                                                             steps=int(np.ceil(test_generator_resnet50_image.samples/test_generator_resnet50_image.batch_size)))\n",
    "#Best model for log(ufp_num) based on audio: ln_ufp_num, audio, ResNet50, raw\n",
    "ln_ufp_num_ResNet50_audio_raw_model = load_model('model_development/models/ln_ufp_num_10s_ma_spec_label_raw,ResNet50_linear_Nadam,audio_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_ufp_num_ResNet50_audio_raw_prediction'] = ln_ufp_num_ResNet50_audio_raw_model.predict(x=test_generator_resnet50_audio, \n",
    "                                                                                             steps=int(np.ceil(test_generator_resnet50_audio.samples/test_generator_resnet50_audio.batch_size)))\n",
    "#Best model for log(ufp_size) based on images: ln_ufp_size, image, ResNet50, raw\n",
    "ln_ufp_size_ResNet50_image_raw_model = load_model('model_development/models/ln_ufp_size_10s_ma_image_label_raw,ResNet50_linear_Nadam,image_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_ufp_size_ResNet50_image_raw_prediction'] = ln_ufp_size_ResNet50_image_raw_model.predict(x=test_generator_resnet50_image, \n",
    "                                                                                             steps=int(np.ceil(test_generator_resnet50_image.samples/test_generator_resnet50_image.batch_size)))\n",
    "#Best model for log(ufp_size) based on audio: ln_ufp_size, audio, Xception, raw\n",
    "ln_ufp_size_Xception_audio_raw_model = load_model('model_development/models/ln_ufp_size_10s_ma_spec_label_raw,Xception_linear_Nadam,audio_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_ufp_size_Xception_audio_raw_prediction'] = ln_ufp_size_Xception_audio_raw_model.predict(x=test_generator_xception_audio,\n",
    "                                                                                                     steps=int(np.ceil(test_generator_xception_audio.samples/test_generator_xception_audio.batch_size)))\n",
    "#Best model for log(noise) based on images: ln_noise, image, ResNet50, raw\n",
    "ln_noise_ResNet50_image_raw_model = load_model('model_development/models/ln_noise_10s_ma_image_label_raw,ResNet50_linear_Nadam,image_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_noise_ResNet50_image_raw_prediction'] = ln_noise_ResNet50_image_raw_model.predict(x=test_generator_resnet50_image,\n",
    "                                                                                               steps=int(np.ceil(test_generator_resnet50_image.samples/test_generator_resnet50_image.batch_size)))\n",
    "\n",
    "#Best model for log(noise) based on audio: ln_noise, audio, Xception, raw\n",
    "ln_noise_Xception_audio_raw_model = load_model('model_development/models/ln_noise_10s_ma_spec_label_raw,Xception_linear_Nadam,audio_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_noise_Xception_audio_raw_prediction'] = ln_noise_Xception_audio_raw_model.predict(x=test_generator_xception_audio, \n",
    "                                                                                             steps=int(np.ceil(test_generator_xception_audio.samples/test_generator_xception_audio.batch_size)))               \n",
    "\n",
    "#Save dataframe with all predictions added\n",
    "metadata.to_csv(path_or_buf='compiled data/metadata_gopro_training_only_UFP_V2_V3_04042024_predictions_added.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e88271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract data from DataFrame\n",
    "epochs = res['epoch']\n",
    "train_loss = res['loss']\n",
    "val_loss = res['val_loss']\n",
    "\n",
    "# Plotting loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
