{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf731a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/R/lib:/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server\n",
      "/usr/lib/R/lib:/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['LD_LIBRARY_PATH'])\n",
    "!echo $LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e9af9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scottweichenthal/Dropbox/IMAGINE Project/MSSI_Project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 14:56:24.277181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.277475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.277716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.277953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.304086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.304401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.304639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.304877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.305110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.305345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.305571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:56:24.305798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_hub as hub\n",
    "from keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# for figures\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import seaborn as sns\n",
    "\n",
    "# for the Grad-CAMs\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#Working Directory on A4 Computer (GoPro and V2 data are on the A4 Computer)\n",
    "\n",
    "files = os.listdir()\n",
    "    \n",
    "os.chdir(\"/home/scottweichenthal/Dropbox/IMAGINE Project/MSSI_Project/\")\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "\n",
    "#This code allows GPU memory allocation to grow as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6368edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  5 14:56:39 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000               On  | 00000000:01:00.0  On |                  Off |\n",
      "| 41%   39C    P8              16W / 140W |    141MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4000               On  | 00000000:21:00.0 Off |                  Off |\n",
      "| 41%   37C    P8              14W / 140W |     17MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A4000               On  | 00000000:4B:00.0 Off |                  Off |\n",
      "| 41%   34C    P8              16W / 140W |     17MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A4000               On  | 00000000:4C:00.0 Off |                  Off |\n",
      "| 41%   38C    P8              12W / 140W |     17MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1700      G   /usr/lib/xorg/Xorg                           39MiB |\n",
      "|    0   N/A  N/A      2357      G   /usr/lib/xorg/Xorg                           47MiB |\n",
      "|    0   N/A  N/A      2482      G   /usr/bin/gnome-shell                         35MiB |\n",
      "|    1   N/A  N/A      1700      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A      2357      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    2   N/A  N/A      1700      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    2   N/A  N/A      2357      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    3   N/A  N/A      1700      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    3   N/A  N/A      2357      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU memory\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d47e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n",
      "TensorFlow Hub version: 0.16.1\n",
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "#  Prints the Tensorflow, Keras versions, and number of GPUs\n",
    "print(tf.__version__)\n",
    "print(K.__version__)\n",
    "print(\"TensorFlow Hub version:\", hub.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0557a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "#Which Python Version\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f449af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata for compiled data you want to use for CNN model development\n",
    "#This version has GoPro in trn and val sets\n",
    "#metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_15012024.csv\", low_memory=False)\n",
    "\n",
    "#This version has GoPro data only in trn set (as opposed to random split between trn,val,tst)\n",
    "# metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04042024.csv\", low_memory=False)\n",
    "# Train: 100% GoPro + 80% Imagine V2\n",
    "# Val: 10% Imagine V2\n",
    "# Tst: 10% Imagine V2\n",
    "# External Test: 100% Imagine V3\n",
    "\n",
    "\n",
    "#This compiled file incorporate all existing data with GoPro in training set only. Rishabh Please use this file!\n",
    "\n",
    "metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04252024.csv\", low_memory=False)\n",
    "# Train: 100% GoPro + 80% Imagine V2 and V3\n",
    "# Val: 10% Imagine V2 and V3\n",
    "# Tst: 10% Imagine V2 and V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69309e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>image_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>ln_ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_num_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_image_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_spec_label_raw</th>\n",
       "      <th>ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>ufp_size_10s_ma_spec_label_quartile</th>\n",
       "      <th>ufp_size_10s_ma_image_label_quartile</th>\n",
       "      <th>image_extension</th>\n",
       "      <th>audio_extension</th>\n",
       "      <th>image_name</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>pair_pm25</th>\n",
       "      <th>set_V3ext</th>\n",
       "      <th>set</th>\n",
       "      <th>vsby_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-23T10:20:27Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.744668</td>\n",
       "      <td>9.744668</td>\n",
       "      <td>3.098740</td>\n",
       "      <td>3.098740</td>\n",
       "      <td>4.319752</td>\n",
       "      <td>4.319752</td>\n",
       "      <td>17063.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-23T10:20:28Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.710145</td>\n",
       "      <td>9.710145</td>\n",
       "      <td>3.119276</td>\n",
       "      <td>3.119276</td>\n",
       "      <td>4.309322</td>\n",
       "      <td>4.309322</td>\n",
       "      <td>16484.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-23T10:20:29Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.683153</td>\n",
       "      <td>9.683153</td>\n",
       "      <td>3.144583</td>\n",
       "      <td>3.144583</td>\n",
       "      <td>4.327702</td>\n",
       "      <td>4.327702</td>\n",
       "      <td>16045.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-23T10:20:30Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.583558</td>\n",
       "      <td>9.583558</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>4.320018</td>\n",
       "      <td>4.320018</td>\n",
       "      <td>14524.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-23T10:20:31Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.509259</td>\n",
       "      <td>9.509259</td>\n",
       "      <td>3.184698</td>\n",
       "      <td>3.184698</td>\n",
       "      <td>4.303119</td>\n",
       "      <td>4.303119</td>\n",
       "      <td>13484.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-23T10:20:32Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.479069</td>\n",
       "      <td>9.479069</td>\n",
       "      <td>3.197448</td>\n",
       "      <td>3.197448</td>\n",
       "      <td>4.277360</td>\n",
       "      <td>4.277360</td>\n",
       "      <td>13083.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-23T10:20:33Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.422544</td>\n",
       "      <td>9.422544</td>\n",
       "      <td>3.211650</td>\n",
       "      <td>3.211650</td>\n",
       "      <td>4.273606</td>\n",
       "      <td>4.273606</td>\n",
       "      <td>12364.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-04-23T10:20:34Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.399638</td>\n",
       "      <td>9.399638</td>\n",
       "      <td>3.223664</td>\n",
       "      <td>3.223664</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>12084.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-04-23T10:20:35Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.403107</td>\n",
       "      <td>9.403107</td>\n",
       "      <td>3.235536</td>\n",
       "      <td>3.235536</td>\n",
       "      <td>4.227709</td>\n",
       "      <td>4.227709</td>\n",
       "      <td>12126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-04-23T10:20:36Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.406976</td>\n",
       "      <td>9.406976</td>\n",
       "      <td>3.241029</td>\n",
       "      <td>3.241029</td>\n",
       "      <td>4.200804</td>\n",
       "      <td>4.200804</td>\n",
       "      <td>12173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime                                         image_path  \\\n",
       "0  2019-04-23T10:20:27Z  archived files no longer used/GoPro Model/data...   \n",
       "1  2019-04-23T10:20:28Z  archived files no longer used/GoPro Model/data...   \n",
       "2  2019-04-23T10:20:29Z  archived files no longer used/GoPro Model/data...   \n",
       "3  2019-04-23T10:20:30Z  archived files no longer used/GoPro Model/data...   \n",
       "4  2019-04-23T10:20:31Z  archived files no longer used/GoPro Model/data...   \n",
       "5  2019-04-23T10:20:32Z  archived files no longer used/GoPro Model/data...   \n",
       "6  2019-04-23T10:20:33Z  archived files no longer used/GoPro Model/data...   \n",
       "7  2019-04-23T10:20:34Z  archived files no longer used/GoPro Model/data...   \n",
       "8  2019-04-23T10:20:35Z  archived files no longer used/GoPro Model/data...   \n",
       "9  2019-04-23T10:20:36Z  archived files no longer used/GoPro Model/data...   \n",
       "\n",
       "                                          audio_path  \\\n",
       "0  archived files no longer used/GoPro Model/data...   \n",
       "1  archived files no longer used/GoPro Model/data...   \n",
       "2  archived files no longer used/GoPro Model/data...   \n",
       "3  archived files no longer used/GoPro Model/data...   \n",
       "4  archived files no longer used/GoPro Model/data...   \n",
       "5  archived files no longer used/GoPro Model/data...   \n",
       "6  archived files no longer used/GoPro Model/data...   \n",
       "7  archived files no longer used/GoPro Model/data...   \n",
       "8  archived files no longer used/GoPro Model/data...   \n",
       "9  archived files no longer used/GoPro Model/data...   \n",
       "\n",
       "   ln_ufp_num_10s_ma_image_label_raw  ln_ufp_num_10s_ma_spec_label_raw  \\\n",
       "0                           9.744668                          9.744668   \n",
       "1                           9.710145                          9.710145   \n",
       "2                           9.683153                          9.683153   \n",
       "3                           9.583558                          9.583558   \n",
       "4                           9.509259                          9.509259   \n",
       "5                           9.479069                          9.479069   \n",
       "6                           9.422544                          9.422544   \n",
       "7                           9.399638                          9.399638   \n",
       "8                           9.403107                          9.403107   \n",
       "9                           9.406976                          9.406976   \n",
       "\n",
       "   ln_ufp_size_10s_ma_image_label_raw  ln_ufp_size_10s_ma_spec_label_raw  \\\n",
       "0                            3.098740                           3.098740   \n",
       "1                            3.119276                           3.119276   \n",
       "2                            3.144583                           3.144583   \n",
       "3                            3.167583                           3.167583   \n",
       "4                            3.184698                           3.184698   \n",
       "5                            3.197448                           3.197448   \n",
       "6                            3.211650                           3.211650   \n",
       "7                            3.223664                           3.223664   \n",
       "8                            3.235536                           3.235536   \n",
       "9                            3.241029                           3.241029   \n",
       "\n",
       "   ln_noise_10s_ma_image_label_raw  ln_noise_10s_ma_spec_label_raw  \\\n",
       "0                         4.319752                        4.319752   \n",
       "1                         4.309322                        4.309322   \n",
       "2                         4.327702                        4.327702   \n",
       "3                         4.320018                        4.320018   \n",
       "4                         4.303119                        4.303119   \n",
       "5                         4.277360                        4.277360   \n",
       "6                         4.273606                        4.273606   \n",
       "7                         4.260000                        4.260000   \n",
       "8                         4.227709                        4.227709   \n",
       "9                         4.200804                        4.200804   \n",
       "\n",
       "   ufp_num_10s_ma_image_label_raw  ...  ufp_size_10s_ma_spec_label_quartile  \\\n",
       "0                         17063.0  ...                                  NaN   \n",
       "1                         16484.0  ...                                  NaN   \n",
       "2                         16045.0  ...                                  NaN   \n",
       "3                         14524.0  ...                                  NaN   \n",
       "4                         13484.0  ...                                  NaN   \n",
       "5                         13083.0  ...                                  NaN   \n",
       "6                         12364.0  ...                                  NaN   \n",
       "7                         12084.0  ...                                  NaN   \n",
       "8                         12126.0  ...                                  NaN   \n",
       "9                         12173.0  ...                                  NaN   \n",
       "\n",
       "   ufp_size_10s_ma_image_label_quartile  image_extension  audio_extension  \\\n",
       "0                                   NaN              NaN              NaN   \n",
       "1                                   NaN              NaN              NaN   \n",
       "2                                   NaN              NaN              NaN   \n",
       "3                                   NaN              NaN              NaN   \n",
       "4                                   NaN              NaN              NaN   \n",
       "5                                   NaN              NaN              NaN   \n",
       "6                                   NaN              NaN              NaN   \n",
       "7                                   NaN              NaN              NaN   \n",
       "8                                   NaN              NaN              NaN   \n",
       "9                                   NaN              NaN              NaN   \n",
       "\n",
       "   image_name  audio_name  pair_pm25  set_V3ext  set  vsby_nm  \n",
       "0         NaN         NaN        NaN        trn  trn     30.0  \n",
       "1         NaN         NaN        NaN        trn  trn     30.0  \n",
       "2         NaN         NaN        NaN        trn  trn     30.0  \n",
       "3         NaN         NaN        NaN        trn  trn     30.0  \n",
       "4         NaN         NaN        NaN        trn  trn     30.0  \n",
       "5         NaN         NaN        NaN        trn  trn     30.0  \n",
       "6         NaN         NaN        NaN        trn  trn     30.0  \n",
       "7         NaN         NaN        NaN        trn  trn     30.0  \n",
       "8         NaN         NaN        NaN        trn  trn     30.0  \n",
       "9         NaN         NaN        NaN        trn  trn     30.0  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at data\n",
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679ebd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "image_path\n",
      "audio_path\n",
      "ln_ufp_num_10s_ma_image_label_raw\n",
      "ln_ufp_num_10s_ma_spec_label_raw\n",
      "ln_ufp_size_10s_ma_image_label_raw\n",
      "ln_ufp_size_10s_ma_spec_label_raw\n",
      "ln_noise_10s_ma_image_label_raw\n",
      "ln_noise_10s_ma_spec_label_raw\n",
      "ufp_num_10s_ma_image_label_raw\n",
      "ufp_num_10s_ma_spec_label_raw\n",
      "ufp_size_10s_ma_image_label_raw\n",
      "ufp_size_10s_ma_spec_label_raw\n",
      "noise_10s_ma_image_label_raw\n",
      "noise_10s_ma_spec_label_raw\n",
      "temp_airp\n",
      "wspd_airp\n",
      "year\n",
      "city\n",
      "pm25\n",
      "file_exists\n",
      "hardware\n",
      "site_id\n",
      "device_id\n",
      "file\n",
      "noise_10s_ma_spec_label_quartile\n",
      "noise_10s_ma_image_label_quartile\n",
      "ufp_num_10s_ma_spec_label_quartile\n",
      "ufp_num_10s_ma_image_label_quartile\n",
      "ufp_size_10s_ma_spec_label_quartile\n",
      "ufp_size_10s_ma_image_label_quartile\n",
      "image_extension\n",
      "audio_extension\n",
      "image_name\n",
      "audio_name\n",
      "pair_pm25\n",
      "set_V3ext\n",
      "set\n",
      "vsby_nm\n"
     ]
    }
   ],
   "source": [
    "#Look at variable names\n",
    "for col in metadata.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d534aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trn    345680\n",
       "val     22407\n",
       "tst     22223\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much data in trn, val, tst sets for metadata_random_split\n",
    "\n",
    "metadata.set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121002b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_num_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_image_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_spec_label_raw</th>\n",
       "      <th>ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>ufp_num_10s_ma_spec_label_raw</th>\n",
       "      <th>ufp_size_10s_ma_image_label_raw</th>\n",
       "      <th>ufp_size_10s_ma_spec_label_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>pm25</th>\n",
       "      <th>device_id</th>\n",
       "      <th>noise_10s_ma_spec_label_quartile</th>\n",
       "      <th>noise_10s_ma_image_label_quartile</th>\n",
       "      <th>ufp_num_10s_ma_spec_label_quartile</th>\n",
       "      <th>ufp_num_10s_ma_image_label_quartile</th>\n",
       "      <th>ufp_size_10s_ma_spec_label_quartile</th>\n",
       "      <th>ufp_size_10s_ma_image_label_quartile</th>\n",
       "      <th>pair_pm25</th>\n",
       "      <th>vsby_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>3.903100e+05</td>\n",
       "      <td>3.903100e+05</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>390310.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>359005.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>223147.000000</td>\n",
       "      <td>390039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.301744</td>\n",
       "      <td>9.302244</td>\n",
       "      <td>3.513263</td>\n",
       "      <td>3.513208</td>\n",
       "      <td>4.115388</td>\n",
       "      <td>4.115988</td>\n",
       "      <td>1.512980e+04</td>\n",
       "      <td>1.513813e+04</td>\n",
       "      <td>36.045195</td>\n",
       "      <td>36.040962</td>\n",
       "      <td>...</td>\n",
       "      <td>6.629045</td>\n",
       "      <td>28.877045</td>\n",
       "      <td>1.446513</td>\n",
       "      <td>1.429632</td>\n",
       "      <td>1.481508</td>\n",
       "      <td>1.479643</td>\n",
       "      <td>1.554374</td>\n",
       "      <td>1.555392</td>\n",
       "      <td>6.911002</td>\n",
       "      <td>21.609274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.779956</td>\n",
       "      <td>0.779607</td>\n",
       "      <td>0.385172</td>\n",
       "      <td>0.384935</td>\n",
       "      <td>0.118462</td>\n",
       "      <td>0.119192</td>\n",
       "      <td>2.221654e+04</td>\n",
       "      <td>2.205105e+04</td>\n",
       "      <td>13.837587</td>\n",
       "      <td>13.835993</td>\n",
       "      <td>...</td>\n",
       "      <td>3.997787</td>\n",
       "      <td>5.682456</td>\n",
       "      <td>1.124708</td>\n",
       "      <td>1.114186</td>\n",
       "      <td>1.118695</td>\n",
       "      <td>1.118875</td>\n",
       "      <td>1.129159</td>\n",
       "      <td>1.129161</td>\n",
       "      <td>6.502780</td>\n",
       "      <td>8.166993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.895912</td>\n",
       "      <td>2.906901</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.598134</td>\n",
       "      <td>3.598134</td>\n",
       "      <td>1.810000e+01</td>\n",
       "      <td>1.830000e+01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666429</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.812397</td>\n",
       "      <td>8.812073</td>\n",
       "      <td>3.255401</td>\n",
       "      <td>3.255015</td>\n",
       "      <td>4.041471</td>\n",
       "      <td>4.040768</td>\n",
       "      <td>6.717000e+03</td>\n",
       "      <td>6.714825e+03</td>\n",
       "      <td>25.930000</td>\n",
       "      <td>25.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.626583</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.214500</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.317678</td>\n",
       "      <td>9.317849</td>\n",
       "      <td>3.564732</td>\n",
       "      <td>3.563883</td>\n",
       "      <td>4.121798</td>\n",
       "      <td>4.122608</td>\n",
       "      <td>1.113310e+04</td>\n",
       "      <td>1.113500e+04</td>\n",
       "      <td>35.330000</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.105735</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.799500</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.831824</td>\n",
       "      <td>9.832088</td>\n",
       "      <td>3.790985</td>\n",
       "      <td>3.790985</td>\n",
       "      <td>4.197052</td>\n",
       "      <td>4.199455</td>\n",
       "      <td>1.861688e+04</td>\n",
       "      <td>1.862180e+04</td>\n",
       "      <td>44.300000</td>\n",
       "      <td>44.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.358984</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.310000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.074470</td>\n",
       "      <td>14.446425</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>4.618876</td>\n",
       "      <td>4.627910</td>\n",
       "      <td>3.521756e+06</td>\n",
       "      <td>1.879329e+06</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.562680</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.094250</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ln_ufp_num_10s_ma_image_label_raw  ln_ufp_num_10s_ma_spec_label_raw  \\\n",
       "count                      390310.000000                     390310.000000   \n",
       "mean                            9.301744                          9.302244   \n",
       "std                             0.779956                          0.779607   \n",
       "min                             2.895912                          2.906901   \n",
       "25%                             8.812397                          8.812073   \n",
       "50%                             9.317678                          9.317849   \n",
       "75%                             9.831824                          9.832088   \n",
       "max                            15.074470                         14.446425   \n",
       "\n",
       "       ln_ufp_size_10s_ma_image_label_raw  ln_ufp_size_10s_ma_spec_label_raw  \\\n",
       "count                       390310.000000                      390310.000000   \n",
       "mean                             3.513263                           3.513208   \n",
       "std                              0.385172                           0.384935   \n",
       "min                              2.302585                           2.302585   \n",
       "25%                              3.255401                           3.255015   \n",
       "50%                              3.564732                           3.563883   \n",
       "75%                              3.790985                           3.790985   \n",
       "max                              5.703782                           5.703782   \n",
       "\n",
       "       ln_noise_10s_ma_image_label_raw  ln_noise_10s_ma_spec_label_raw  \\\n",
       "count                    390310.000000                   390310.000000   \n",
       "mean                          4.115388                        4.115988   \n",
       "std                           0.118462                        0.119192   \n",
       "min                           3.598134                        3.598134   \n",
       "25%                           4.041471                        4.040768   \n",
       "50%                           4.121798                        4.122608   \n",
       "75%                           4.197052                        4.199455   \n",
       "max                           4.618876                        4.627910   \n",
       "\n",
       "       ufp_num_10s_ma_image_label_raw  ufp_num_10s_ma_spec_label_raw  \\\n",
       "count                    3.903100e+05                   3.903100e+05   \n",
       "mean                     1.512980e+04                   1.513813e+04   \n",
       "std                      2.221654e+04                   2.205105e+04   \n",
       "min                      1.810000e+01                   1.830000e+01   \n",
       "25%                      6.717000e+03                   6.714825e+03   \n",
       "50%                      1.113310e+04                   1.113500e+04   \n",
       "75%                      1.861688e+04                   1.862180e+04   \n",
       "max                      3.521756e+06                   1.879329e+06   \n",
       "\n",
       "       ufp_size_10s_ma_image_label_raw  ufp_size_10s_ma_spec_label_raw  ...  \\\n",
       "count                    390310.000000                   390310.000000  ...   \n",
       "mean                         36.045195                       36.040962  ...   \n",
       "std                          13.837587                       13.835993  ...   \n",
       "min                          10.000000                       10.000000  ...   \n",
       "25%                          25.930000                       25.920000  ...   \n",
       "50%                          35.330000                       35.300000  ...   \n",
       "75%                          44.300000                       44.300000  ...   \n",
       "max                         300.000000                      300.000000  ...   \n",
       "\n",
       "                pm25      device_id  noise_10s_ma_spec_label_quartile  \\\n",
       "count  359005.000000  223147.000000                     223147.000000   \n",
       "mean        6.629045      28.877045                          1.446513   \n",
       "std         3.997787       5.682456                          1.124708   \n",
       "min         0.666429      18.000000                          0.000000   \n",
       "25%         3.626583      28.000000                          0.000000   \n",
       "50%         6.105735      29.000000                          1.000000   \n",
       "75%         8.358984      30.000000                          2.000000   \n",
       "max        46.562680      41.000000                          3.000000   \n",
       "\n",
       "       noise_10s_ma_image_label_quartile  ufp_num_10s_ma_spec_label_quartile  \\\n",
       "count                      223147.000000                       223147.000000   \n",
       "mean                            1.429632                            1.481508   \n",
       "std                             1.114186                            1.118695   \n",
       "min                             0.000000                            0.000000   \n",
       "25%                             0.000000                            0.000000   \n",
       "50%                             1.000000                            1.000000   \n",
       "75%                             2.000000                            2.000000   \n",
       "max                             3.000000                            3.000000   \n",
       "\n",
       "       ufp_num_10s_ma_image_label_quartile  \\\n",
       "count                        223147.000000   \n",
       "mean                              1.479643   \n",
       "std                               1.118875   \n",
       "min                               0.000000   \n",
       "25%                               0.000000   \n",
       "50%                               1.000000   \n",
       "75%                               2.000000   \n",
       "max                               3.000000   \n",
       "\n",
       "       ufp_size_10s_ma_spec_label_quartile  \\\n",
       "count                        223147.000000   \n",
       "mean                              1.554374   \n",
       "std                               1.129159   \n",
       "min                               0.000000   \n",
       "25%                               1.000000   \n",
       "50%                               2.000000   \n",
       "75%                               3.000000   \n",
       "max                               3.000000   \n",
       "\n",
       "       ufp_size_10s_ma_image_label_quartile      pair_pm25        vsby_nm  \n",
       "count                         223147.000000  223147.000000  390039.000000  \n",
       "mean                               1.555392       6.911002      21.609274  \n",
       "std                                1.129161       6.502780       8.166993  \n",
       "min                                0.000000       0.356000       0.380000  \n",
       "25%                                1.000000       3.214500      15.000000  \n",
       "50%                                2.000000       4.799500      15.000000  \n",
       "75%                                3.000000       8.310000      30.000000  \n",
       "max                                3.000000      80.094250      60.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6eaefca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What input are you using: images, or spectrograms? spectrograms\n"
     ]
    }
   ],
   "source": [
    "#Select input file type (this tells python where to look for the file paths)\n",
    "file = input(\"What input are you using: images, or spectrograms? \")\n",
    "\n",
    "if file == 'images':\n",
    "    file = 'image_path'\n",
    "else:\n",
    "  if file == 'spectrograms':\n",
    "      file = 'audio_path'\n",
    "  else:\n",
    "    print('!!!TYPO in input_data name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e16d5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Initial Learning Rate\n",
    "initial_learning_rate = 1e-4\n",
    "meta_data_name = \"gp_v2_v3_Training_Only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afbd75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 score function\n",
    "# import keras.backend as Ke\n",
    "# def r2_score(y_true, y_pred):\n",
    "#     SS_res = Ke.sum(Ke.square(y_true - y_pred))\n",
    "#     SS_tot = Ke.sum(Ke.square(y_true - Ke.mean(y_true)))\n",
    "#     return 1 - SS_res / (SS_tot + Ke.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02a203d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What architecture do you want to use: Xception_linear_Nadam, ResNet50_linear_Nadam, Xception_linear_Nadam_l2_regularization, ConvNeXT_linear_Nadam, ViT_linear_Nadam ?Xception_linear_Nadam\n"
     ]
    }
   ],
   "source": [
    "# Model architectures\n",
    "def preprocess_image(image):\n",
    "    # Resize the image to 224x224 pixels\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    # Normalize the pixel values to [-1, 1]\n",
    "    image = (image / 127.5) - 1.0\n",
    "    return image\n",
    "\n",
    "architecture = input(\"What architecture do you want to use: Xception_linear_Nadam, ResNet50_linear_Nadam, Xception_linear_Nadam_l2_regularization, ConvNeXT_linear_Nadam, ViT_linear_Nadam ?\")\n",
    "if architecture == 'Xception_linear_Nadam':\n",
    "    architecture_preprocessing = K.applications.xception.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.Xception(include_top=False, weights = \"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units= 1, activation='linear')(model_output) \n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "            loss = 'mse',\n",
    "            metrics = ['mae']\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "elif architecture == 'Xception_linear_Nadam_l2_regularization':\n",
    "    architecture_preprocessing = K.applications.xception.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.Xception(include_top=False, weights=\"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        # Adding L2 regularization to the Dense layer\n",
    "        model_output = K.layers.Dense(units=1, activation='linear', kernel_regularizer=l2(0.01))(model_output)\n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "                    \n",
    "elif architecture == 'ResNet50_linear_Nadam':\n",
    "    architecture_preprocessing = K.applications.resnet50.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ResNet50(include_top=False, weights= \"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units= 1, activation='linear')(model_output) \n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "            loss = 'mse',\n",
    "            metrics = ['mae']\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "elif architecture == 'ConvNeXT_linear_Nadam':\n",
    "    architecture_preprocessing = K.applications.convnext.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ConvNeXtBase(model_name=\"convnext_base\",include_top=False, weights=\"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(model_output) \n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.Nadam(learning_rate=initial_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "elif architecture == 'ViT_linear_Nadam':\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(224, 224, 3), dtype='float32', name='input')\n",
    "        vit_layer = hub.KerasLayer(\"https://tfhub.dev/sayakpaul/vit_b16_fe/1\", trainable=True)(model_input)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(vit_layer)\n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "                          \n",
    "else:\n",
    "    print('!!!TYPO in architecture name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f002aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scottweichenthal/Dropbox/IMAGINE Project/MSSI_Project\n",
      "What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ?ln_noise_10s_ma_image_label_raw\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'architecture_preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18982/918505364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ln_noise_10s_ma_image_label_raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n\u001b[0m\u001b[1;32m     10\u001b[0m                                                      \u001b[0mhorizontal_flip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                      vertical_flip = False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'architecture_preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "# Select Exposure to be modelled (CNN & Xception)\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "target = input(\"What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ?\")                  \n",
    "\n",
    "if target == 'ln_noise_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "elif target == 'ln_noise_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_num_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    \n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "elif target == 'ln_ufp_num_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    " \n",
    "    \n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.hdf5', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "else:\n",
    "    print('!!!TYPO in exposure name') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8812d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scottweichenthal/Dropbox/IMAGINE Project/MSSI_Project\n",
      "What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ?ln_ufp_num_10s_ma_spec_label_raw\n",
      "Found 345680 validated image filenames.\n",
      "Found 22407 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Exposures optimized for ViT\n",
    "\n",
    "# Select Exposure to be modelled\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "target = input(\"What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ?\")                  \n",
    "\n",
    "if target == 'ln_noise_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_image, \n",
    "                                                         horizontal_flip=True,\n",
    "                                                         vertical_flip=False)\n",
    "\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                    x_col=file, \n",
    "                                                    y_col=target,  \n",
    "                                                    class_mode='raw', \n",
    "                                                    target_size=(224, 224), # resize all images to 224 x 224 for ViT\n",
    "                                                    color_mode='rgb', \n",
    "                                                    batch_size=128,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                       x_col=file,\n",
    "                                                       y_col=target,\n",
    "                                                       class_mode='raw',\n",
    "                                                       target_size=(224, 224),\n",
    "                                                       color_mode='rgb',\n",
    "                                                       batch_size=128,\n",
    "                                                       shuffle=False)\n",
    "\n",
    "    # Generate a unique timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # Base filepath for checkpoints\n",
    "    base_checkpoint_filepath = f'./rishabh_model_files/models/{target},{architecture},{file},{meta_data_name}_Combined_IMAGINE_goproUFP_V2_V3_{timestamp}'\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = K.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "elif target == 'ln_noise_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_image, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(224, 224), # resize all images to 224 x 224 for ViT\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_num_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_image, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(224, 224), # resize all images to 224 x 224 for ViT\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    \n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "elif target == 'ln_ufp_num_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_image, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file,\n",
    "                                                y_col= target,\n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(224, 224), # resize all images to 224 x 224 for ViT\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_image, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(224, 224), # resize all images to 224 x 224 for ViT\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    " \n",
    "    \n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_image, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file,\n",
    "                                                y_col= target,\n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(224, 224), # resize all images to 224 x 224 for ViT\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    " \n",
    "else:\n",
    "    print('!!!TYPO in exposure name') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ddf55d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 14:58:21.083188: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 14:58:21.360520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.360919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.361274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.361624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.361980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.362324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.362663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.363003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.363342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.363705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.364038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:21.364345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.435396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.435701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.435951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.436197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.436431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.436664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.436890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.437117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.437347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.437581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14104 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-06-05 14:58:22.437867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.438077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14236 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-06-05 14:58:22.438292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.438500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14236 MB memory:  -> device: 2, name: NVIDIA RTX A4000, pci bus id: 0000:4b:00.0, compute capability: 8.6\n",
      "2024-06-05 14:58:22.438716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-05 14:58:22.438924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14236 MB memory:  -> device: 3, name: NVIDIA RTX A4000, pci bus id: 0000:4c:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2024-06-05 14:58:30.519704: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_33943\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 200 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 200 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 200 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 200 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2024-06-05 14:59:16.248097: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x55e64b1f9bf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 14:59:16.248145: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2024-06-05 14:59:16.248154: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (1): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2024-06-05 14:59:16.248162: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (2): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2024-06-05 14:59:16.248170: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (3): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2024-06-05 14:59:16.439206: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 14:59:17.331893: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-06-05 14:59:17.811209: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-06-05 14:59:18.547485: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-06-05 14:59:19.762899: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-06-05 14:59:26.589568: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 14:59:26.704526: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - ETA: 0s - loss: 0.1663 - mae: 0.2347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:38:31.072458: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_3581108\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:39\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2024-06-05 16:46:04.803840: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 6462s 2s/step - loss: 0.1663 - mae: 0.2347 - val_loss: 0.0775 - val_mae: 0.2179 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "2701/2701 [==============================] - ETA: 0s - loss: 0.0426 - mae: 0.1489INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 6318s 2s/step - loss: 0.0426 - mae: 0.1489 - val_loss: 0.0506 - val_mae: 0.1621 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "2701/2701 [==============================] - ETA: 0s - loss: 0.0315 - mae: 0.1237INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 6301s 2s/step - loss: 0.0315 - mae: 0.1237 - val_loss: 0.0464 - val_mae: 0.1540 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "2701/2701 [==============================] - 6335s 2s/step - loss: 0.0265 - mae: 0.1096 - val_loss: 0.0508 - val_mae: 0.1628 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "2701/2701 [==============================] - ETA: 0s - loss: 0.0230 - mae: 0.0992INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 6365s 2s/step - loss: 0.0230 - mae: 0.0992 - val_loss: 0.0445 - val_mae: 0.1518 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "2701/2701 [==============================] - ETA: 0s - loss: 0.0202 - mae: 0.0910INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 6322s 2s/step - loss: 0.0202 - mae: 0.0910 - val_loss: 0.0374 - val_mae: 0.1323 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "2701/2701 [==============================] - ETA: 0s - loss: 0.0179 - mae: 0.0844INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 6378s 2s/step - loss: 0.0179 - mae: 0.0844 - val_loss: 0.0372 - val_mae: 0.1303 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1209/2701 [============>.................] - ETA: 53:59 - loss: 0.0156 - mae: 0.0782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - ETA: 0s - loss: 0.0160 - mae: 0.0789INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ViT_linear_Nadam,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701/2701 [==============================] - 6347s 2s/step - loss: 0.0160 - mae: 0.0789 - val_loss: 0.0362 - val_mae: 0.1271 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1784/2701 [==================>...........] - ETA: 33:29 - loss: 0.0144 - mae: 0.0746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model = get_compiled_model()\n",
    "    \n",
    "\n",
    "#Fit Model\n",
    "model.fit(train_generator,\n",
    "          validation_data=validate_generator,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=int(np.ceil(train_generator.samples/train_generator.batch_size)),\n",
    "          validation_steps=int(np.ceil(validate_generator.samples/validate_generator.batch_size)),\n",
    "          callbacks=[csv_logger, \n",
    "                     reduce_lr_on_plateau, \n",
    "                     model_checkpoint,\n",
    "                     early_stopping] \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4502660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#Identify Best Epoch\n",
    "res = pd.read_csv(filepath_or_buffer='./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "res = res.sort_values('val_loss', ascending=True).reset_index(drop=True)\n",
    "best_epoch = res.epoch[0]\n",
    "print(best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Generate Predictions for compiled data, add them to dataframe, save new dataframe #####\n",
    "\n",
    "#Load Metadata\n",
    "#metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_15012024.csv\", low_memory=False)\n",
    "\n",
    "#This version has GoPro data only in trn set (as opposed to random split between trn,val,tst)\n",
    "#metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04042024.csv\", low_memory=False)\n",
    "metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04252024.csv\", low_memory=False)\n",
    "\n",
    "# check to see if each image file exists and remove rows from the results dataframe for which image files don't exist.\n",
    "metadata['file_exists'] = metadata.apply(lambda row: os.path.isfile(row.image_path), axis = 1)\n",
    "\n",
    "#Remove missing files from metadata to avoid errors in adding predictions to dataframe\n",
    "metadata = metadata.loc[metadata['file_exists'] == True]\n",
    "metadata.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Predictions and Add to Database\n",
    "\n",
    "#Define Preprocessing functions\n",
    "architecture_preprocessing_resnet50 = K.applications.resnet50.preprocess_input\n",
    "architecture_preprocessing_xception = K.applications.xception.preprocess_input\n",
    "\n",
    "\n",
    "#Define Test Generators\n",
    "generator_tst_resnet50 = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing_resnet50, \n",
    "                                                     horizontal_flip=False,\n",
    "                                                     vertical_flip = False)\n",
    "\n",
    "generator_tst_xception = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing_xception, \n",
    "                                                     horizontal_flip=False,\n",
    "                                                     vertical_flip = False)\n",
    "\n",
    "test_generator_resnet50_audio = generator_tst_resnet50.flow_from_dataframe(dataframe=metadata[['audio_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'audio_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "test_generator_resnet50_image = generator_tst_resnet50.flow_from_dataframe(dataframe=metadata[['image_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'image_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "test_generator_xception_audio = generator_tst_xception.flow_from_dataframe(dataframe=metadata[['audio_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'audio_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "test_generator_xception_image = generator_tst_xception.flow_from_dataframe(dataframe=metadata[['image_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'image_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "                                                                       \n",
    "######### - Generate Predictions for Best CNN Models - ##############\n",
    "\n",
    "\n",
    "\n",
    "#Best model for log(ufp_num) based on images:  ln_ufp_num, image, ResNet50, raw\n",
    "ln_ufp_num_ResNet50_image_raw_model = load_model('model_development/models/ln_ufp_num_10s_ma_image_label_raw,ResNet50_linear_Nadam,image_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_ufp_num_ResNet50_image_raw_prediction'] = ln_ufp_num_ResNet50_image_raw_model.predict(x=test_generator_resnet50_image, \n",
    "                                                                                             steps=int(np.ceil(test_generator_resnet50_image.samples/test_generator_resnet50_image.batch_size)))\n",
    "#Best model for log(ufp_num) based on audio: ln_ufp_num, audio, ResNet50, raw\n",
    "ln_ufp_num_ResNet50_audio_raw_model = load_model('model_development/models/ln_ufp_num_10s_ma_spec_label_raw,ResNet50_linear_Nadam,audio_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_ufp_num_ResNet50_audio_raw_prediction'] = ln_ufp_num_ResNet50_audio_raw_model.predict(x=test_generator_resnet50_audio, \n",
    "                                                                                             steps=int(np.ceil(test_generator_resnet50_audio.samples/test_generator_resnet50_audio.batch_size)))\n",
    "#Best model for log(ufp_size) based on images: ln_ufp_size, image, ResNet50, raw\n",
    "ln_ufp_size_ResNet50_image_raw_model = load_model('model_development/models/ln_ufp_size_10s_ma_image_label_raw,ResNet50_linear_Nadam,image_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_ufp_size_ResNet50_image_raw_prediction'] = ln_ufp_size_ResNet50_image_raw_model.predict(x=test_generator_resnet50_image, \n",
    "                                                                                             steps=int(np.ceil(test_generator_resnet50_image.samples/test_generator_resnet50_image.batch_size)))\n",
    "#Best model for log(ufp_size) based on audio: ln_ufp_size, audio, Xception, raw\n",
    "ln_ufp_size_Xception_audio_raw_model = load_model('model_development/models/ln_ufp_size_10s_ma_spec_label_raw,Xception_linear_Nadam,audio_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_ufp_size_Xception_audio_raw_prediction'] = ln_ufp_size_Xception_audio_raw_model.predict(x=test_generator_xception_audio,\n",
    "                                                                                                     steps=int(np.ceil(test_generator_xception_audio.samples/test_generator_xception_audio.batch_size)))\n",
    "#Best model for log(noise) based on images: ln_noise, image, ResNet50, raw\n",
    "ln_noise_ResNet50_image_raw_model = load_model('model_development/models/ln_noise_10s_ma_image_label_raw,ResNet50_linear_Nadam,image_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_noise_ResNet50_image_raw_prediction'] = ln_noise_ResNet50_image_raw_model.predict(x=test_generator_resnet50_image,\n",
    "                                                                                               steps=int(np.ceil(test_generator_resnet50_image.samples/test_generator_resnet50_image.batch_size)))\n",
    "\n",
    "#Best model for log(noise) based on audio: ln_noise, audio, Xception, raw\n",
    "ln_noise_Xception_audio_raw_model = load_model('model_development/models/ln_noise_10s_ma_spec_label_raw,Xception_linear_Nadam,audio_path,GoPro_Training_Only_Combined_IMAGINE_v2_GoPro.hdf5')\n",
    "metadata['ln_noise_Xception_audio_raw_prediction'] = ln_noise_Xception_audio_raw_model.predict(x=test_generator_xception_audio, \n",
    "                                                                                             steps=int(np.ceil(test_generator_xception_audio.samples/test_generator_xception_audio.batch_size)))               \n",
    "\n",
    "#Save dataframe with all predictions added\n",
    "metadata.to_csv(path_or_buf='compiled data/metadata_gopro_training_only_UFP_V2_V3_04042024_predictions_added.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68e88271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABGQklEQVR4nO3deXxU1f3/8dcnCQRC2GSTTfZdIMEACgLJ1LZarVprq9aKW926WGtrtbWtdPH3bau16rdav2jdqi21Wq2tqBUhgFIVEcQFVEQQUBGQVdbA+f1xZshkmEkmyUzuzOT9fDzuY7Y7cz8zd5K8c86555pzDhERERFpWnlBFyAiIiLSHCmEiYiIiARAIUxEREQkAAphIiIiIgFQCBMREREJgEKYiIiISAAUwqTezGyVmR2Xxte/zMzWm9kOM+uUru1I9jKze83sV0muW2lm32jgdhr83FxmZk+a2blpfP1pZvZA+PoR4d8F+enaXiaoz3dacodCmGQUM2sB3AR8zjlX7JzbFHRNDWVm3c3scTP7wMycmfWNebzQzO42s21m9pGZXRlQqZIFzOyL4e/JYVH3nWJm68ysfRq3ezAQRTjnTnDO3ZeubcZs6/3w74L9TbG9ZJhZefhn+raY+58zs/MCKkuykEKYZJpuQCvgjaALSYEDwFPAlxM8Pg0YBPQBKoAfmtnxTVOapIuZFaTjdZ1z/wJmA78Pb6cD8EfgMufc1nRsszlLYj9+CkyN/edKpD4UwqTBwv8hP2Rm95vZdjN7w8zKknieM7OBUbfvNbNfmdlg4K3w3VvMbHbU+peb2Uoz22hmN5hZrd9dMzsv/F/pjWa22czeM7MToh6v0aUa0/3RN7zN881sTfj5l5rZWDNbamZbzOwPdb1P59x659ztwMIEq0wFfumc2+ycWwbcCZwXrqGVmT1gZpvC21toZt3qeM+V4c9xQbj75l9m1snMHgy3ti2M/oNhZreE3982M1tkZpPqek9mNs7MXg4/Z72Z3RTzmV0cbvn70My+H/W8PDO7xszeDb+nh2JadI4N170lXNN5ddUS9dyOZvZvM9sQ3lf/NrNeMasNMLOXzGyrmf0zZttHR237VTMrT3bb4eefZ2bPm9nvzewTYJqZDTCz2eH3ujG8DzqE1z/fzP4V9fwVZvZQ1O01ZlaSYHOXAyeY2efxYWyuc+7xqOeOMLNnzOyT8P75cfj+hJ9/bfvO/D8FPwbOCH+nXg3ff7CbNvzaPzGz1Wb2sfnfB+1jXvtcM3s//FlcW8/PN/IaBVHb/mX4M99uZv8xs85R6yfcn+HPfln4eSvN7JKox8rNbK2ZXW1mHwH31FHaFuBe4LoEdSf8DoQfLzWzV8K1/A3/z2fksVq/01bPn3XJXAph0lgnAzOADsDjQJ3hJBHn3NvAiPDNDs65UNTDXwLKgDHAKcAFSbzkeHyo6wz8FviTmVk9ShqPb6k6A7gZuBY4LlzjV81sSj1eqwYz6wj0AF6NuvtVqt//uUB7oDfQCbgU2JXES58JnAP0BAYA/8X/MTkMWEbNPxgLgZLwY38B/m5mrajdLcAtzrl24dd/KObxCvxn9jngGqsOupcDpwJT8O97M3Ab+DE/wJPA/wJdwjUtSeK9RuSF32Mf4Aj85xT7PZyK/870AKqAW8Pb7gk8AfwK/zn8AHjEzLrUY/vgvysrga7A9YAB/xPe3jD8fpwWXncuMCkcXroDLYCJ4Xr6A8XA0ngbcc5tBL4LPAichP9cCT+3LTAL3/raAxgIPBt+OOHnH+WQfeecewr4f8Dfwl2Co+OUdV54qQAi9cd+/scCQ4DPAD8zs2Hx3l89fA04H/95t8Tvt2T258f4z61d+Pm/N7MxUa97ePh5fYCLk6jjeuDLZjYkzmMJvwNm1hJ4DPhzeHt/p2aLeTLf6fr8rEuGUgiTxnrOOTczPF7jz0C8X9Kp8Bvn3CfOuffxgeisJJ6z2jl3Z7i2+4Du+O7OZP3SObfbOfcffNfDX51zHzvn1gHzgdL6vYUaisOX0d1IW4G24ev78OFroHNuv3NukXNuWxKve49z7t1w99STwLvOuVnOuSr8L/qDNTvnHnDObXLOVTnnfgcU4v9Q1mYfMNDMOjvndjjnXoh5/OfOuU+dc6/h/yBE9tMlwLXOubXOuT34P0anh1s3zgZmOef+6pzbF65pSRLvNfI+NjnnHnHO7XTObcf/YYwNyH92zr3unPsU+Ck+ROcDXwdmhr/DB5xzzwAvA19IdvthHzjn/jf8We5yzq1wzj3jnNvjnNuAH+c4JVzvSmA7PmxOAZ4G1pnZ0PDt+c65A7Vs6wV8QP9P+LUjTgI+cs79Lvy93e6cezH8WG2ff0SifVeXs4GbnHMrnXM7gB8BZ8Z57V3OuVfx/2w09vfEPc65t51zu/D/CJSE7691fzrnngj/fDjn3FzgP0B0C/AB4Lrwfqvznx7n3EfAHcAv4jyW8DsAHI0P3zeHv/MPE9VinuR3OumfdclcCmHSWB9FXd8JtLL0jIlZE3V9Nf6/y7ocrM05tzN8tTjBuvGsj7q+K87t+rxWrB3hy3ZR97XD/3EGH2ifBmaEu4h+a/6ghbokXbOZfT/cNbPVzLbg/7B3pnYXAoOB5eEuj5NiHk+0n/oAj4a7iLbg/1Pfjw/FvYF3k3hvcZlZkZn9X7g7bBswD+hgNY+mi62rBf699gG+EqkrXNux+MBeH9Gvj5l1NbMZ5gfNbwMeoOZnOxcoByaHr1fi/8hOCd+uzXTgfuALZjYh6v7aPsfaPv947yHZnzHC662OeW5BzGvH/p5ozM9Oba9X6/40sxPM7AXz3bVb8OEser9scM7trmctvwE+b2Y1gmUd34EewDrnnIt6yuqo5ybznU7n7ydpIgphEoSdQFHU7cOTeE7vqOtHAB80soZPG1BDyjjnNgMfUrNFYDThAxLC/x3/3Dk3HJiAb+WYmqrtmx//dTXwVaCjc64DviWu1u5a59w7zrmz8N1AvwEeNrM2Uask2k9rgBOccx2illbhVsU1+O6Uhvo+vgVvfLibdHLkbdZS1z5gY3jbf46pq41z7tf1rMHF3P6f8H2jwjV9PaaeSAibFL4+lyRCmJldGH4v38SP1boz3LUFtX+OtX3+EYn2Xex7i/UBPvxEP7eKmqGgqSTcn2ZWCDwC3Ah0C3/nZ1Jzv9T1Xg/h/BHcNwO/jHmotu/Ah0DPmOERR0RdT+Y7LTlAIUyCsAT4mpnlmx/4m8zYqqvCg1V748fE/C0FNZxpZi3MH0xweiNfL67wGKvC8M3CmDFX9wM/Cb+vocBF+IG+mFmFmY0M/+e7DR8aUnmIflv8H8oNQIGZ/YyarXJxmdnXzaxLuLtsS/ju6Lp+Gv4vfgR+zE1kP90BXG9mfcKv08XMTgk/9iBwnJl91cwKwgOMS+r5XnbhD+Y4jPhjYb5uZsPNrAjfdfRwuJv6AeCLZvb58PexlfkB2rED++urLb61c0t4nNJVMY/PxY+hau2cW4vv3j4e3wW9OLJSeAD2tPD1HsANwEXhLsU7gE34sYoA/wYON7MrzE9/0tbMxocfq+3zj0i079YDfS3xwTB/Bb5nZv3MrJjqMWRVSXxOqVbb/myJ/1ncAFSZP1Dncyna7k34f5aix7rV9h34L/7n7/Lwd/40YFzMc+v6TksOUAiTIHwX+CL+j/jZ+AGqdfknsAgfnp4A/tTIGn6KbzXYDPwcPzA9HXZR3fW4nJqD66/Ddx+txv9RvsH5gdDgW+YexgewZeHHa8zV1EhP48eRvB3e/m5iutQSOB54w8x24AfpnxnTfTMXWIEfEH6j8+PpCK/7OPAfM9uOH9c0Hvw8UPhuoe8Dn+D3cX3GDN0MtMa3bL2AH5ge68/4gPsR/ii0y8PbXoM/0OPH+D/Oa/B/LBv7u/Hn+INItuK/r/+IftD5g1B24MMXzo/3Wwk872rOh9UbeD58/XZghnMu8hyHD+5XmNmI8Nihz+J/tj4C3sEHPajl84+SaN/9PXy5ycxeifNe78Z/vvOA9/Dfpe/U9uGkS237M/z5XI4fQ7YZP7j/8QQvVd/tbsMf/HNY1N0JvwPOub3AafgDGjbjD/6J/o7cTN3fackBVrNLWiTzmJkDBjnnVgRdi8Rn/nD494AWAbWA5Jxw683fnXPHpHk7fdG+EwlEWiYVFBGRxgl3U6Y1gIlIsNQdKSln1ed6i7ccUfcrJL2dOxJs445UbSPTaqjlc61zotV6bOPJBNv4caq2kWQdbySo4+ymrCNcS+DftVyTKd+zRMzsxwnqezLo2iR3qDtSREREJABqCRMREREJgEKYiIiISACybmB+586dXd++fdO+nU8//ZQ2bdrUvaJkJO2/7Kd9mP20D7Ob9l9qLFq0aKNzLu75aLMuhPXt25eXX3457duprKykvLw87duR9ND+y37ah9lP+zC7af+lhpmtTvSYuiNFREREAqAQJiIiIhIAhTARERGRAGTdmDAREZHmYt++faxdu5bdu3fXvXKKtW/fnmXLljX5drNVq1at6NWrFy1atEj6OQphIiIiGWrt2rW0bduWvn37YmZNuu3t27fTtm3bJt1mtnLOsWnTJtauXUu/fv2Sfp66I0VERDLU7t276dSpU5MHMKkfM6NTp071brFUCBMREclgCmDZoSH7SSFMRERE4tq0aRMlJSWUlJRw+OGH07Nnz4O39+7dW+tzX375ZS6//PI6tzFhwoSU1FpZWclJJ52UktdqKhoTJiIiInF16tSJJUuWADBt2jSKi4v5wQ9+cPDxqqoqCgriR4mysjLKysrq3MaCBQtSUms2UkuYiIiIJO28887jyiuvpKKigquvvpqXXnqJCRMmUFpayoQJE3jrrbeAmi1T06ZN44ILLqC8vJz+/ftz6623Hny94uLig+uXl5dz+umnM3ToUM4++2yccwDMnDmToUOHcuyxx3L55ZfX2eL1ySefcOqppzJq1CiOPvpoli5dCsDcuXMPtuSVlpayfft2PvzwQyZPnkxJSQlHHnkk8+fPT/lnlohawkRERLLAFVdAuFEqZUpK4Oab6/+8t99+m1mzZpGfn8+2bduYN28eBQUFzJo1ix//+Mc88sgjhzxn+fLlzJkzh+3btzNkyBAuu+yyQ6ZzWLx4MW+88QY9evRg4sSJPP/885SVlXHJJZcwb948+vXrx1lnnVVnfddddx2lpaU89thjzJ49m6lTp7JkyRJuvPFGbrvtNiZOnMiOHTto1aoV06dP5/Of/zzXXnst+/fvZ+fOnfX/QBpIISzGp5/CnDmwf78+GhERkXi+8pWvkJ+fD8DWrVs599xzeeeddzAz9u3bF/c5J554IoWFhRQWFtK1a1fWr19Pr169aqwzbty4g/eVlJSwatUqiouL6d+//8GpH8466yymT59ea33PPffcwSAYCoXYtGkTW7duZeLEiVx55ZWcffbZnHbaafTq1YuxY8dywQUXsG/fPk499VRKSkoa89HUi5JGjGXL4ItfhJ/85DBOOSXoakRERLyGtFilS5s2bQ5e/+lPf0pFRQWPPvooq1atSnjS78LCwoPX8/PzqaqqSmqdSJdkfcR7jplxzTXXcOKJJzJz5kyOPvpoZs2axeTJk5k3bx5PPPEE55xzDldddRVTp06t9zYbQmPCYpSWQvv2sHhxh6BLERERyXhbt26lZ8+eANx7770pf/2hQ4eycuVKVq1aBcDf/va3Op8zefJkHnzwQcCPNevcuTPt2rXj3XffZeTIkVx99dWUlZWxfPlyVq9eTdeuXbnooou48MILeeWVV1L+HhJRS1iM/HyYMgVefrlj0KWIiIhkvB/+8Iece+653HTTTYRCoZS/fuvWrbn99ts5/vjj6dy5M+PGjavzOdOmTeP8889n1KhRFBUVcd999wFw8803M2fOHPLz8xk+fDgnnHACM2bM4IYbbqBFixYUFxdz//33p/w9JGINaeYLUllZmXv55ZfTuo1bbvEDIFevhiOOSOumJE0iR9lI9tI+zH7ah423bNkyhg0bFsi2M+m0RTt27KC4uBjnHN/61rcYNGgQ3/ve94Iu6xDx9peZLXLOxZ2rQ92RcVRU+Ms5c4KtQ0RERODOO++kpKSEESNGsHXrVi655JKgS0oJdUfGceSR0L79XmbPbsm55wZdjYiISPP2ve99LyNbvhpLLWFx5OVBSckWZs+GLOutFRERkSyhEJZAaekW1q6Fd98NuhIRERHJRQphCZSWbgZg9uyACxEREZGcpBCWQO/eu+jeXYPzRUREJD0UwhIwg1AIjQsTEZFmq7y8nKeffrrGfTfffDPf/OY3a31OZCqpL3zhC2zZsuWQdaZNm8aNN95Y67Yfe+wx3nzzzYO3f/aznzFr1qx6VB9f9InFg6YQVotQCD7+GKK+AyIiIs3GWWedxYwZM2rcN2PGjKROog0wc+ZMOnTo0KBtx4awX/ziFxx33HENeq1MpRBWC80XJiIizdnpp5/Ov//9b/bs2QPAqlWr+OCDDzj22GO57LLLKCsrY8SIEVx33XVxn9+3b182btwIwPXXX8+QIUM47rjjeOuttw6uc+eddzJ27FhGjx7Nl7/8ZXbu3MmCBQt4/PHHueqqqygpKeHdd9/lvPPO4+GHHwbg2WefpbS0lJEjR3LBBRccrK9v375cd911jBkzhpEjR7J8+fJa398nn3zCqaeeyqhRozj66KNZunQpAHPnzqWkpISSkhJKS0vZvn07H374IZMnT6akpIQjjzyS+fPnN+7DRfOE1apfP+jb13dJfvvbQVcjIiLN2hVXwJIlqX3NkpJazwzeqVMnxo0bx1NPPcUpp5zCjBkzOOOMMzAzrr/+eg477DD279/PZz7zGZYuXcqoUaPivs6iRYuYMWMGixcvpqqqijFjxnDUUUcBcNppp3HRRRcB8JOf/IQ//elPfOc73+Hkk0/mpJNO4vTTT6/xWrt37+a8887j2WefZfDgwUydOpU//vGPXHHFFQB07tyZV155hdtvv50bb7yRu+66K+H7u+666ygtLeWxxx5j9uzZTJ06lSVLlnDjjTdy2223MXHiRHbs2EGrVq2YPn06n//857n22mvZv38/O3fuTP5zTkAtYXUIhaCyEg4cCLoSERGRphfdJRndFfnQQw8xZswYSktLeeONN2p0HcaaP38+X/rSlygqKqJdu3acfPLJBx97/fXXmTRpEiNHjuTBBx/kjTfeqLWet956i379+jF48GAAzj33XObNm3fw8dNOOw2Ao4466uBJvxN57rnnOOeccwAIhUJs2rSJrVu3MnHiRK688kpuvfVWtmzZQkFBAWPHjuWee+5h2rRpvPbaayk5pZNawupQUQF33w2vvgqlpUFXIyIizVYtLVbpdOqpp3LllVfyyiuvsGvXLsaMGcN7773HjTfeyMKFC+nYsSPnnXceu3fvrvV1zCzu/eeddx6PPfYYo0eP5t5776WysrLW16nrnNeFhYUA5OfnU1VVVe/XMjOuueYaTjzxRGbOnMnRRx/NrFmzmDx5MvPmzeOJJ57gnHPO4aqrrmLq1Km1vn5d1BJWh8i4MM0XJiIizVFxcTHl5eVccMEFB1vBtm3bRps2bWjfvj3r16/nySefrPU1Jk+ezKOPPsquXbvYvn07//rXvw4+tn37drp3786+fft48MEHD97ftm1btm/ffshrDR06lFWrVrFixQoA/vznPzNlypQGvbfJkycf3GZlZSWdO3emXbt2vPvuu4wcOZKrr76asrIyli9fzurVq+natSsXXXQRF154Ia+88kqDthlNLWF16NkTBg/2g/O///2gqxEREWl6Z511FqeddtrBbsnRo0dTWlrKiBEj6N+/PxMnTqz1+WPGjOGMM86gpKSEPn36MGnSpIOP/fKXv2T8+PH06dOHkSNHHgxeZ555JhdddBG33nrrwQH5AK1ateKee+7hK1/5ClVVVYwdO5ZLL720Qe9r2rRpnH/++YwaNYqioiLuu+8+wE/DMWfOHPLz8xk+fDgnnHACM2bM4IYbbqBFixYUFxdz//33N2ib0ayuZr1MU1ZW5iLzj6RTZWUl5eXlAFx2GTzwAHzyCbRokfZNSwpE7z/JTtqH2U/7sPGWLVvGsGHDAtn29u3bUzLuqTmJt7/MbJFzrize+uqOTEIoBDt2wKJFQVciIiIiuUIhLAmRf+Q0X5iIiIikikJYErp0gZEjNThfREREUidtIczM7jazj83s9QSPm5ndamYrzGypmY1JVy2pUFEBzz8P4Ul5RUREmkS2jd1urhqyn9LZEnYvcHwtj58ADAovFwN/TGMtjRYKwa5d8OKLQVciIiLNRatWrdi0aZOCWIZzzrFp0yZatWpVr+elbYoK59w8M+tbyyqnAPc7/816wcw6mFl359yH6aqpMaZMgbw83yU5eXLQ1YiISHPQq1cv1q5dy4YNG5p827t37653qGjOWrVqRa9ever1nCDnCesJrIm6vTZ83yEhzMwuxreW0a1btzpn002FHTt2HLKdgQOP4tFH91NeviTt25fGibf/JLtoH2Y/7cPstmPHDoqLi4MuI6usXr26XusHGcLinb8gbnurc246MB38PGFNMe9MvPltTjnFnzVi3LhyiorSXoI0guYnyn7ah9lP+zC7af+lX5BHR64Fekfd7gV8EFAtSamogH37YMGCoCsRERGRbBdkCHscmBo+SvJoYGumjgeLOPZYKCjQVBUiIiLSeGnrjjSzvwLlQGczWwtcB7QAcM7dAcwEvgCsAHYC56erllRp2xbGjVMIExERkcZL59GRZ9XxuAO+la7tp0tFBfz617BtG7RrF3Q1IiIikq00Y349hUKwfz/Mnx90JSIiIpLNFMLq6ZhjoGVLdUmKiIhI4yiE1VPr1jBhgk7mLSIiIo2jENYAoRAsWQKffBJ0JSIiIpKtFMIaoKICnIO5c4OuRERERLKVQlgDjBsHRUUaFyYiIiINpxDWAC1bwqRJCmEiIiLScAphDVRRAW++CevXB12JiIiIZCOFsAYKhfyljpIUERGRhlAIa6DSUj9jvkKYiIiINIRCWAMVFMCUKRoXJiIiIg2jENYIoRCsWAFr1gRdiYiIiGQbhbBGqKjwl+qSFBERkfpSCGuEkSOhUyd1SYqIiEj9KYQ1Ql4elJf7ljDngq5GREREsolCWCOFQvD++7ByZdCViIiISDZRCGukyHxh6pIUERGR+lAIa6QhQ+DwwzU4X0REROpHIayRzHxr2OzZGhcmIiIiyVMIS4GKCn8OyWXLgq5EREREsoVCWAroPJIiIiJSXwphKdCvH/Tpo8H5IiIikjyFsBQw812SlZVw4EDQ1YiIiEg2UAhLkVAIPvkEli4NuhIRERHJBgphKRI5j6S6JEVERCQZCmEp0qsXDBqkwfkiIiKSHIWwFAqFYO5cqKoKuhIRERHJdAphKVRRAdu3wyuvBF2JiIiIZDqFsBQqL/eXGhcmIiIidVEIS6Fu3eDIIxXCREREpG4KYSlWUQHPPQd79wZdiYiIiGQyhbAUC4Vg1y548cWgKxEREZFMphCWYlOm+Bn0NVWFiIiI1EYhLMU6doTSUo0LExERkdophKVBKAT//a/vlhQRERGJRyEsDSoq/MD8BQuCrkREREQylUJYGkyaBPn56pIUERGRxBTC0qBtWxg7VoPzRUREJDGFsDQJheCll/xpjERERERiKYSlSSgE+/fD/PlBVyIiIiKZSCEsTSZMgJYt1SUpIiIi8SmEpUnr1nDMMRqcLyIiIvEphKVRRQUsXgyffBJ0JSIiIpJpFMLSKBQC52DevKArERERkUyjEJZG48f7bkl1SYqIiEgshbA0atkSjj1Wg/NFRETkUAphaRYKweuvw/r1QVciIiIimUQhLM0qKvxlZWWgZYiIiEiGUQhLs6OO8qcxUpekiIiIRFMIS7OCApgyRYPzRUREpCaFsCZQUQHvvANr1wZdiYiIiGSKtIYwMzvezN4ysxVmdk2cx9ub2b/M7FUze8PMzk9nPUEJhfyluiRFREQkIm0hzMzygduAE4DhwFlmNjxmtW8BbzrnRgPlwO/MrGW6agrKqFFw2GHqkhQREZFq6WwJGwescM6tdM7tBWYAp8Ss44C2ZmZAMfAJUJXGmgKRlwfl5T6EORd0NSIiIpIJ0hnCegJrom6vDd8X7Q/AMOAD4DXgu865A2msKTChELz/Prz3XtCViIiISCYoSONrW5z7YtuBPg8sAULAAOAZM5vvnNtW44XMLgYuBujWrRuVTTDp1o4dO1K6nTZtioBx/PGPyznxxI9S9roSX6r3nzQ97cPsp32Y3bT/0i+dIWwt0Dvqdi98i1e084FfO+ccsMLM3gOGAi9Fr+Scmw5MBygrK3Pl5eXpqvmgyspKUrkd5+Caa+CDD4ZSXj40Za8r8aV6/0nT0z7MftqH2U37L/3S2R25EBhkZv3Cg+3PBB6PWed94DMAZtYNGAKsTGNNgTHzXZIaFyYiIiKQxhDmnKsCvg08DSwDHnLOvWFml5rZpeHVfglMMLPXgGeBq51zG9NVU9AqKuCjj+Ctt4KuRERERIKWzu5InHMzgZkx990Rdf0D4HPprCGTROYLmz0bhqpHUkREpFnTjPlNqH9/6N1b84WJiIiIQliTiowLq6yEAzk5EYeIiIgkSyGsiYVCsGkTvPZa0JWIiIhIkBTCmlhFhb/UeSRFRESaN4WwJta7NwwcqHFhIiIizZ1CWAAqKmDuXKjKubNkioiISLIUwgIQCsG2bbB4cdCViIiISFAUwgIQGRemLkkREZHmSyEsAN26wfDhGpwvIiLSnCmEBSQUgvnzYe/eoCsRERGRICiEBaSiAnbuhJdeCroSERERCYJCWECmTPEz6KtLUkREpHlSCAtIp05QUqLB+SIiIs2VQliAKirgv/+FXbuCrkRERESamkJYgEIh2LPHBzERERFpXhTCAjRpEuTnq0tSRESkOVIIC1C7dlBWpsH5IiIizZFCWMBCIT9NxfbtQVciIiIiTUkhLGAVFf5E3s89F3QlIiIi0pQUwgI2cSK0aKEuSRERkeZGISxgRUVwzDEanC8iItLcKIRlgIoKWLwYNm8OuhIRERFpKgphGSAUggMHYN68oCsRERGRpqIQlgHGj4dWrdQlKSIi0pwohGWAwkI49lgNzhcREWlOFMIyRCgEr70GGzYEXYmIiIg0BYWwDFFR4S8rKwMtQ0RERJqIQliGKCuDtm01LkxERKS5UAjLEAUF/oTeCmEiIiLNg0JYBgmF4O23Yd26oCsRERGRdFMIyyChkL/UUZIiIiK5TyEsg4weDR07KoSJiIg0BwphGSQvD8rLNS5MRESkOVAIyzAVFbBqFbz3XtCViIiISDophGUYjQsTERFpHhTCMszw4dC1q7okRUREcp1CWIYx812Ss2eDc0FXIyIiIumiEJaBQiH48EM/Z5iIiIjkJoWwDBQZF6YuSRERkdylEJaBBgyAXr00OF9ERCSXKYRlIDPfGjZnDhw4EHQ1IiIikg4KYRmqogI2boTXXw+6EhEREUkHhbAMVVHhL9UlKSIikpsUwjJUnz5+bJgG54uIiOQmhbAMVlEBc+fC/v1BVyIiIiKpphCWwUIh2LoVFi8OuhIRERFJNYWwDFZe7i/VJSkiIpJ7FMIyWPfuMGyYBueLiIjkIoWwDBcKwfz5sG9f0JWIiIhIKiUVwsysjZnlha8PNrOTzaxFeksT8IPzP/0UFi4MuhIRERFJpWRbwuYBrcysJ/AscD5wb7qKkmoaFyYiIpKbkg1h5pzbCZwG/K9z7kvA8DqfZHa8mb1lZivM7JoE65Sb2RIze8PM5iZfevPQqROMHq0QJiIikmuSDmFmdgxwNvBE+L6COp6QD9wGnIAPbGeZ2fCYdToAtwMnO+dGAF9JvvTmIxSCBQtg9+6gKxEREZFUSTaEXQH8CHjUOfeGmfUH6jpmbxywwjm30jm3F5gBnBKzzteAfzjn3gdwzn2cdOXNSCgEe/bAf/8bdCUiIiKSKkmFMOfcXOfcyc6534QH6G90zl1ex9N6Amuibq8N3xdtMNDRzCrNbJGZTU268mZk0iTIy1OXpIiISC6ptUsxwsz+AlwK7AcWAe3N7Cbn3A21PS3OfS7O9o8CPgO0Bv5rZi84596O2f7FwMUA3bp1o7KyMpmyG2XHjh1Nsp1kDR48hscec3zmM5o+PxmZtv+k/rQPs5/2YXbT/ku/pEIYMNw5t83MzgZmAlfjw1htIWwt0Dvqdi/ggzjrbHTOfQp8ambzgNFAjRDmnJsOTAcoKytz5ZFDBtOosrKSpthOsk45BX73OygrK6e4OOhqMl+m7T+pP+3D7Kd9mN20/9Iv2TFhLcLzgp0K/NM5t49DW7ViLQQGmVk/M2sJnAk8HrPOP4FJZlZgZkXAeGBZ0tU3I6EQVFXB888HXYmIiIikQrIh7P+AVUAbYJ6Z9QG21fYE51wV8G3gaXyweig8qP9SM7s0vM4y4ClgKfAScJdz7vWGvJFcN3EitGihcWEiIiK5IqnuSOfcrcCtUXetNrOKJJ43E999GX3fHTG3b6D2bk0B2rSB8eMVwkRERHJFsqctam9mN5nZy+Hld/hWMWlCoRC88gps2RJ0JSIiItJYyXZH3g1sB74aXrYB96SrKIkvFIIDB2DevKArERERkcZKNoQNcM5dF554daVz7udA/3QWJoc6+mho1Qrm1DVNroiIiGS8ZEPYLjM7NnLDzCYCu9JTkiRSWOgH6GtcmIiISPZLNoRdCtxmZqvMbBXwB+CStFUlCVVUwNKlsGFD0JWIiIhIYyR72qJXnXOjgVHAKOdcKRBKa2USVyj8qc+dG2wdIiIi0jjJtoQB4Jzb5pyLzA92ZRrqkTqUlUFxsbokRUREsl29QliMeOeGlDRr0cKf0FuD80VERLJbY0JYXactkjQJhWD5cvgg9kycIiIikjVqDWFmtt3MtsVZtgM9mqhGiVERPleBWsNERESyV60hzDnX1jnXLs7S1jmX1CmPss6GDVBSQt9774VXXwWXeQ1+JSXQoYNCmIiISDZrTHdkbvr4Y2jfnj733+/TzsCBcNVVsGCBn64+A+TnQ3m5BueLiIhkM4WwWCNGwNy5LHj4YZg+HQYPhltu8bOk9uoF3/wmPPMM7NsXaJkVFfDee7BqVaBliIiISAMphCWw77DD4KKL4MknfRflgw/ChAlw333wuc9Bt25w7rnw2GOwc2eT1xeZL0xdkiIiItlJISwZ7dvD174GDz8MGzf64PXFL8K//gVf+hJ06QKnn+6D2pYtTVLSiBF+s+qSFBERyU65Obg+nVq3hlNO8cu+fX7q+n/8wwezRx7xE3l95jM+nJ1yim8xSwMz3yU5Z44/dsA0a5uIiEhWUUtYY7RoAccdB7ffDmvX+sH7V1wBb78Nl1wC3bvD5Mnw+9+nZfBWKATr1sE776T8pUVERCTNFMJSJS8PjjkGfvtbWLHCT2/xs5/B1q1w5ZXQrx8cdRT86lfw5pspmfoiMl+YuiRFRESyj0JYOpjBqFEwbZoPYytWwA03QGEh/PSnfkDXsGHwox/BwoUNDmSDBkHPnhqcLyIiko0UwprCgAHwgx/47sp16+C226B3bx/Mxo2DPn3g8suhshKqqpJ+WTPfJRkZFyYiIiLZQyGsqfXoUT3X2Mcf+ykvxoyBO+/0/Yvdu8OFF8ITT8CePXW+XEWFn0HjjTeaoHYRERFJGYWwIB12GEyd6o+s3LjRT4Hxuc/5y5NO8nNQnHkmPPQQbN8e9yUi84VpXJiIiEh2UQjLFG3awJe/7Oca+/hjP0nsmWf6dHXGGT6QffGLcM89PrCF9enjx/wrhImIiGQXhbBMVFgIxx/vT5v04Ycwbx5cdhksXQoXXACHH+6bwP7wB1i7llDIT1e2f3/QhYuIiEiyFMIyXX4+TJpUPdfYokVwzTXw0Ufwne9A7978unI8F2/5Dcv++XbQ1YqIiEiSFMKyiZkfxB+Za2zZMvh//492xQf4Dddw5JeHwJFH+vnJFi/WIZMiIiIZTCEsmw0dCj/6ES2XLCQ0YDV3DLsFOneG66/3Ya1/f/j+9+H55+HAgaCrFRERkSgKYTli6OeO4AfvX86+Zyp9V+Vdd8Hw4X7c2LHH+qkxLr0Unn4a9u4NulwREZFmTyfwzhGhEPzxj/Dyy3DMMV38XGMXXgjbtsHMmf4k4w88AP/3f9C+PZSUQMeOyS8tWgT9FkVERHKKQliOKC/3l7Nn+1NYHtSunZ/q4swzYdcumDXLz0v2zjvw7ruwebNfPv209g20aePDWIcO9QtvHTv6oz1FRESkBoWwHNG5sz9d5Zw5cO21CVZq3drPNfbFLx762N69sGVLdSira1m1yg/+37wZduyovbjWrasDWX1DXOvWjftgREREMpRCWA4JheCOO2D3bmjVqp5PbtkSunb1S31VVdUvwK1dC6+95q9v21b7axcWNijA5Wncm4iIZDiFsBxSUQE33wwvvFDdPdkkCgp8U1znzvV/7v791QEumSD30Ud+ao7Nm2Hr1oTTcEzKy4OjjvJzrE2e7A9O6NSpUW9TREQklRTCcsjkyZCX57skmzSENUZ+vg9HDQlIBw74IBYb1LZs4f3KSvqsWQO33QY33eTXHz7ch7LIcsQRqX0vIiIi9aAQlkM6dPCNP7Nnw89/HnQ1TSAvr7oLMsZ7gwbRp7wc9uyBhQth/ny//PWv/ghR8CEsOpQNG+YnxBUREWkCCmE5pqLCn+Ho00/9AY3NXmGh74o89lj40Y989+drr1WHsmef9SdNB98ad+yx1aGstFRTc4iISNoohOWYUAh++1s/Sf7nPhd0NRkoP9/PkVZS4s+96ZyfqmP+fH+i9Pnz4Z//9Ou2aQNHH+37eSdNgvHjoagoyOpFRCSHKITlmIkT/Tj52bMVwpJiBgMH+uX88/19H35Y3VI2fz5Mm+bDWosW1YP9J03yH/ZhhwVavoiIZC+FsBxTXOwbbObMCbqSLNa9O3z1q34Bf9TmggXVoeyWW+CGG/xjRx5Zc1xZr16BlS0iItlFISwHhUL+HN5bt/ozFEkjdegAX/iCX8CfeSB6sP8DD/hzRgH07Vs9LcakSTB4sAb7i4hIXAphOaiiAn75Sz/EKd7k+NJIrVv7kDV5sr9dVQWvvlodyp56Cv78Z/9Y1641B/uPHu37i0VEpNnTX4McdMwx/qDAOXMUwppEQYEfK3bUUXDFFX782Ntv1xxX9o9/+HWLi2HChOpQNm6cTs0kItJMKYTloFat/Jjx2bODrqSZMoMhQ/zyjW/4+9atqxnKfvYzH9ZatoSysuouzAkTfPeniIjkvLygC5D0qKjwPWSbNgVdiQDQsyeceaafwX/pUr9j/vWv6paz3/0OTjzRH20ZmT7joYf8kZoiIpKTFMJyVCjkLysrAy1DEunYEU46CX7zG3/k5datvuly2jTo0gXuuQfOOAN69KiePuPuu+GddxKeL1NERLKLuiNz1Nixfq7R2bPhy18OuhqpU1GRb76sqPC39+2DJUuquy///W+4917/2OGH+/7mgQP99e7da162basjMkVEsoBCWI5q0cIPM9J8YVmqRQufpMeOhSuv9K1fy5dXh7L//td3Z+7de+hzi4p8GIsX0CKXhx/uj9zUkZoiIoHRb+AcFgrBD3/ohxV17x50NdIoZv4E48OGwcUX+/ucg82b4aOP/E6OvoxcX7bMN4du3hz/Nbt0iR/Q4rWuiYhISimE5bBIz1ZlJZx1VqClSDqY+YH8hx0Gw4fXvu6ePTXDWez1Dz+EN9/01/ftO/T5bdokDmjR17t29efnFJHMU1UFO3bA9u3VSy23B69cCbNmQbdu/ue7W7fq6+3aadhDCiiE5bDSUj9j/uzZCmHNXmEh9Onjl9ocOOBbzWJb1qKD2+uv+1/MW7Yc+vy8vJqta7V1iRYXp+WtiuSMqqr4QamO8JTwvt27k9uuGbRtS+e8PJg5E/bvP3SdwsLqYJboMnK9uFiBLQGFsByWnw9Tpmi+MKmHvDzo1MkvRx5Z+7q7dsH69bUHttde8+tUVR36/DZtah2z1nbVKujc2Y9xiyytW/vxciKZKBKaGhuWIreTDU15eT7otG1bvRQX+3+6om9HP17bfUVFYMaCykrKJ0/2U+qsX+9/pqMvI9dXr4YXX4QNG/w/crFat647qEUu27RJ7T7JcAphOS4Ugscf9z8jdTWCiNRL69b+XJl9+9a+3oED/pd4vKAWuVy6FJ5+GrZtO/i0oxK9XosW1YEsOqClcmnd2v9hk9zgnO+S37ULdu5M/rKudT79tGZ42rMnuXrihaa2bf0/P3UFpXjPa906fS1NkdbtLl3q/sds/37YuDF+UItcvvsuPP+8Xy/edDuRoQ+1BbXIfUVF6XnPTSitIczMjgduAfKBu5xzv06w3ljgBeAM59zD6aypuYnMFzZnDpx3XqClSHMV/Ut85Mja192582A4WzpvHqMGDqz+Yxi9RP+RjF7Wr49/f0PmVissTF/IKyryp7bIy/OLWfVlZMl1zvnxh40JQfUJUg35DpjVDObRl23a+O90bCBKptUpnaEpSPn51QFp1Kja162q8i1n8YJa5PKtt2Du3MSzjrdtW3tQi36sVavUv98USFsIM7N84Dbgs8BaYKGZPe6cezPOer8Bnk5XLc3ZiBG+R2f2bIUwyQJFRdC/P/Tvzyf79kF5eeNfM9IKEi+c1Rboals2bTr0vmS7jpIVG87iBbZkLoNa14xR69f7MJsoIMXrukpGvFAUuezUKfFj9b1s2TI3w1ImKCjwww+SOXR/3z74+OPaA9ubbyY+Ehz8AOl4Ae2YY6pbKwKQzpawccAK59xKADObAZwCvBmz3neAR4Cxaayl2crL80dJzpnj/xbp94k0O2b+v+BWrfyRpOly4IAPYskGuUjrzIEDfolcr+syXeum4fXzd+/2R9F16BA/5DQkGBUW6hdZc9OihT/1W8+eda+7Z0/dgW3pUvjPf/yZSr7znZwNYT2BNVG31wLjo1cws57Al4AQtYQwM7sYuBigW7duVDbBuXh27NjRJNtpCj179mDt2sE8+OCL9Oq1K+hymkQu7b/mKqf2YcuWfmlmJ2ffsWMHxQ09Cnb37tS3Lkq9ZP3PYJs2MGCAX+LI27sXq6pif4DvMZ0hLN6/KrGd8jcDVzvn9lst/9k456YD0wHKyspceSq6KOpQWVlJU2ynKXTvDjffDDt3jk9J7042yKX911xpH2Y/7cPspv2Xfuk8/Gct0Dvqdi/gg5h1yoAZZrYKOB243cxOTWNNzdLgwf480JqqQkREJHOksyVsITDIzPoB64Azga9Fr+Cc6xe5bmb3Av92zj2WxpqaJTM/LuyZZzQuTEREJFOkrSXMOVcFfBt/1OMy4CHn3BtmdqmZXZqu7Up8oZAfq/hm7GERIiIiEoi0zhPmnJsJzIy5744E656Xzlqau8h5JGfP9tNWiIiISLA0JXQz0a+fn9h8zpygKxERERFQCGtWQiGorIx/LlYRERFpWgphzUhFhZ9M+NVXg65EREREFMKakci4MHVJioiIBE8hrBnp2ROGDNF8YSIiIplAIayZqaiAefP8+VBFREQkOAphzUwoBDt2wKJFQVciIiLSvCmENTOR04D9859+9nwREREJhkJYM9OlC0yaBL/+NQwaBD/7GSxfHnRVIiIizY9CWDP0xBNw991+Atfrr4dhw+Coo+Cmm+CD2FOsi4iISFoohDVDbdvC+ef7E3qvXevDlxl8//vQqxccd5wPaVu3Bl2piIhI7lIIa+a6d4fvfQ9eftl3S/70p7BqFVx4IXTrBqefDo8+Cnv2BF2piIhIblEIk4OGDIGf/xzeeQdeeAEuvhjmz4fTTvOB7Bvf8BO9HjgQdKUiIiLZTyFMDmEG48fDrbfCunXw1FNw8snwt7/5KS6OOAJ+8ANYvFhHWIqIiDSUQpjUqqAAPv95uP9+WL8eZsyAMWPgllv85YgRfnD/ypVBVyoiIpJdFMIkaUVFcMYZ8Pjj8NFH8Mc/QufO8JOfwIABMGEC3HYbbNgQdKUiIiKZTyFMGqRTJ7j0Un8KpFWr4H/+B7Zvh29/2w/2/8IX4MEH/ez8IiIiciiFMGm0Pn3gmmvgtddg6VI/Xuz11+HrX/cD+s8+289NpvNVioiIVFMIk5QaOdLPxr9qFcydC+ecA08+CSedBD16wLe+BQsWaEC/iIiIQpikRV4eTJ4Md9zhx4/985/+yMq774aJE6F/f7j2WnjzzaArFRERCYZCmKRdy5bVU1x8/DHcdx8MHuxbzEaMgNJSuOEGP3u/iIhIc6EQJk2qbVuYOhWeftrPQXbzzT6k/fCHfv6xigq4807YvDnoSkVERNJLIUwCc/jh8N3vwosvwttvw3XX+WB28cX+sS99CR5+GHbvDrpSERGR1FMIk4wwaJAPYW+9BQsXwje/6U+d9JWv+CMszz8fZs2C/fuDrlRERCQ1FMIko5hBWRn8/vd+jNgzz/hzVz7yCHz2s9C7N1x5pT/huI6wFBGRbKYQJhkrPx+OOw7uucefMumhh/w5Lf/wBxg7FoYNg1/8AlasCLpSERGR+lMIk6zQurXvmnz0UR/Ipk/348auu853ZUZOOL5+fdCVioiIJEchTLJOx45w0UVQWQnvvw+//S3s2eMH+ffo4U84/sQTh7N0qWbpFxGRzKUQJlmtd2+46ipYssSfKumaa/yRljfeOJTRo6G4GMaMgQsvhP/9X5g/H7ZuDbpqERERKAi6AJFUGTECrr8efvUruO++lygsHMfixT6gPf64n60/on9/KCnxS2mpv+zZ0x8YICIi0hQUwiTnmEHfvjspL4ezzvL3OQcffugDWWRZvBj+8Y/q53XqVB3MIsvQoVCgnxIREUkD/XmRZsHMjxfr0QO+8IXq+7dvh6VLa4azP/zBjzEDKCyEI4+sbi0rKYFRo/zM/yIiIo2hECbNWtu2/oTiEydW31dV5SeNjbSWLVnij8q8667qdQYOPLQ7s3t3dWeKiEjyFMJEYhQU+PFlI0bA2Wf7+5zzp1SK7c58+OHq53Xpcmh35uDB6s4UEZH49OdBJAlm0KuXX046qfr+rVsP7c685RbYu9c/3qqV776MDmYjR/qjNkVEpHlTCBNphPbtYdIkv0Ts2wfLl9dsMfv73/0Es+AD3aBBh3ZnHn54k5cvIiIBUggTSbEWLXxr18iRcM45/j7nYM2ami1mCxf6UzFFdOt2aHfmoEH+9E0iIpJ7FMJEmoAZHHGEX04+ufr+LVvg1VdrhrObbqqe6b+oKH53ZlFRE78BERFJOYUwkQB16ABTpvglYu9eWLasZjCbMQPuuMM/npfnB/wPGeKP0hw4EAYM8Je9e+tAABGRbKFf1yIZpmVLGD3aL+ee6+9zDlavrg5lr74K77wDTz8Nu3dXP7dFC+jXrzqURQe0fv38a4uISGZQCBPJAv4sAH459dTq+w8cgA8+gHffhRUr/BK5/txzfjLaiLw83x0aL6ANGKAuThGRpqYQJpLF8vKqp86I7tIE33q2YUP8gPbww7BpU831e/SIH9AGDvRHgYqISGophInkKDPo2tUvxxxz6ONbtsQPaE895c+zGa1z58QBrXNnnSlARKQhFMJEmqkOHeCoo/wS69NPYeXK6oAWCWnPPQd/+YtvZYto1y5xQOve3bfWiYjIoRTCROQQbdpUz3UWa88eWLXq0IAWOcdmVVX1uq1bQ//+1aFMR3KKiFTTr0ARqZfCQj89xpAhhz5WVeUnpY0NaCtWxD+Ss2/f+AGtb9+mejciIsFRCBORlCko8FNh9OsHn/1szccOHPBjzeIFtHhHcnbqdDQDBlQfeNCzZ/X1Xr38gQSackNEsplCmIg0ibw8H6R69ox/JOfGjTUD2osvbmH//sN5/XV48kk/Ti1W1641g1lsWOvZ03etiohkIoUwEQmcGXTp4pfIkZyVlcspL/dnNXcOtm2DtWth3Tp/Gb2sWuVb0z755NDX7tjx0Fa02Nvt2+sITxFpegphIpLxzHxQat8eRoxIvN7OndUhLTasrVvnDx5Yv77m0Z3gW8tig1lsWOvcWUd6ikhqKYSJSM4oKoJBg/ySyN69fmxaola1OXP8WQj276/5vJYt/Ti02oLa4YfriE8RSV5af12Y2fHALUA+cJdz7tcxj58NXB2+uQO4zDn3ajprEpHmrWVL6NPHL4ns3w8ff1yzFS06qC1cCI89VvNoT/AtZd2719792bOnP8JURCRtIczM8oHbgM8Ca4GFZva4c+7NqNXeA6Y45zab2QnAdGB8umoSEUlGfr4PU927w9ix8ddxzo9Bi+3yjFxftgyeeabmUZ8RXbr4MNa796Eta5FF5/IUyX3pbAkbB6xwzq0EMLMZwCnAwRDmnFsQtf4LQK801iMikjJm0KmTX0aPTrzetm3xx6etWQPvvw8LFhx6Hk/wBxT06lV7UGvbNn3vT0TSz1zsCNVUvbDZ6cDxzrlvhG+fA4x3zn07wfo/AIZG1o957GLgYoBu3bodNWPGjLTUHG3Hjh0UFxenfTuSHtp/2a857cPdu/PYuLGQDRviLxs3FrJ586GTorVpU0Xnznvo0mUPXbv6y9ilTZuqwI78bE77MBdp/6VGRUXFIudcWbzH0tkSFu/HPm7iM7MK4ELg2HiPO+em47sqKSsrc+Xl5SkqMbHKykqaYjuSHtp/2U/7sKY9e+IdSFAQXtqweDF89FH8Iz8jLWeJWtUOOyw9U3RoH2Y37b/0S2cIWwv0jrrdC/ggdiUzGwXcBZzgnIvTKC8iIoWF/jyc/fsnXmffPn9kZ+wRn5Fl1iz/+IEDNZ/XqlXdQU1TdIikXjpD2EJgkJn1A9YBZwJfi17BzI4A/gGc45x7O421iIjkvBYt6j7ys6rKz5W2Zk38oDZvnm9xiz4RO/ijSqOP8owX1rp29Qc1iEhy0hbCnHNVZvZt4Gn8FBV3O+feMLNLw4/fAfwM6ATcbr4tvCpRv6mIiDReQUH16aMSOXCgeoqOeGHtxRfhkUf8nGuxrx09l9qBAwNYtKg6vPXs6R/XFB0iXlrnCXPOzQRmxtx3R9T1bwCHDMQXEZHg5OX5iWcPPxzKEvxbHDnfZySYxYa1V16BNWt68PDDhz63c+fqIJhoSdc4NZFMormdRUSk3qLP91laGn+dOXPmU1JSzrp1JFxeftm3usVq1cq3mkUHs0hrWmTp3t13k4pkK4UwERFJCzM/31nHjnDkkYnXi5xKKjagReZUe+klf7lnz6HP7dq17la1Dh3UqiaZSSFMREQClcyppCJnKEjUorZmDbzwgu8ijVVUVLNVLbZFrWdP3/XaokX63qNIPAphIiKS8aLPUDBqVOL19uzx03DEa1Fbt86foeCDDw49qMAMunWru1WtXTu1qknqKISJiEjOKCyEfv38kkjkoIJErWrvvQfPPedb3mK1aXNoMOvRo7qlrUcPjVWT5CmEiYhIsxJ9UEFJSeL1du2qvVVt3jw/lm3fvkOf26XLoeEs9naXLppXrblTCBMREYmjdWsYMMAviRw44E/A/sEH1YEtcj1ye/FiP0Fu7Cml8vN9q1m8gBZ9XQcW5C6FMBERkQbKy6tuVRs9OvF6VVX+3J6xAS1y/Z13YO5c2Lz50Oe2bl0zqCUKa0VF6Xufkh4KYSIiImlWUFB9JoHaRLpAE7WsLVoEjz/u14vVvn3igBa5rqNAM4tCmIiISIZIpgvUOdi2rWZAiw1rc+b48Wqx5wCNjIerLaxFxqtJ+imEiYiIZBEz3+rVvj0MH554vQMHqo8CTRTWFi6Mf8aCggLo3Hk8oRCUl/tl4ECNTUs1hTAREZEclJfnzyjQtWviU0uBnzNt/fpDA9qCBduZPbs1f/mLX69Hj+pAplCWGgphIiIizVjLltC7t1+iVVa+yZQpXXn7bais9Mvs2SiUpZBCmIiIiMRlBkOG+OWSS/x4NIWy1FEIExERkaTUJ5T17FkzlA0YoFAWSyFMREREGqSuUDZrFjz4oF9XoexQCmEiIiKSEvFC2VtvKZQlohAmIiIiaWEGQ4f65dJLFcpiKYSJiIhIk6hPKOvVq2Yo698/90KZQpiIiIgEoq5Q9swz8MADft1cDGUKYSIiIpIRmlsoUwgTERGRjJTroUwhTERERLJCvFC2fHl1KPvPf7IrlCmEiYiISFYyg2HD/HLZZbWHst69a4ayfv2CD2UKYSIiIpIT6gplTz8Nf/6zX7d3b/jOd+Cqq4KrVyFMREREclJdoayoKNj6FMJERESkWYgNZUHLC7oAERERkeZIIUxEREQkAAphIiIiIgFQCBMREREJgEKYiIiISAAUwkREREQCoBAmIiIiEgCFMBEREZEAKISJiIiIBEAhTERERCQACmEiIiIiAVAIExEREQmAQpiIiIhIAMw5F3QN9WJmG4DVTbCpzsDGJtiOpIf2X/bTPsx+2ofZTfsvNfo457rEeyDrQlhTMbOXnXNlQdchDaP9l/20D7Of9mF20/5LP3VHioiIiARAIUxEREQkAAphiU0PugBpFO2/7Kd9mP20D7Ob9l+aaUyYiIiISADUEiYiIiISAIWwGGZ2vJm9ZWYrzOyaoOuR+jGz3mY2x8yWmdkbZvbdoGuS+jOzfDNbbGb/DroWqT8z62BmD5vZ8vDP4jFB1yT1Y2bfC/8Ofd3M/mpmrYKuKRcphEUxs3zgNuAEYDhwlpkND7Yqqacq4PvOuWHA0cC3tA+z0neBZUEXIQ12C/CUc24oMBrty6xiZj2By4Ey59yRQD5wZrBV5SaFsJrGASuccyudc3uBGcApAdck9eCc+9A590r4+nb8L/+ewVYl9WFmvYATgbuCrkXqz8zaAZOBPwE45/Y657YEWpQ0RAHQ2swKgCLgg4DryUkKYTX1BNZE3V6L/oBnLTPrC5QCLwZcitTPzcAPgQMB1yEN0x/YANwT7lK+y8zaBF2UJM85tw64EXgf+BDY6pz7T7BV5SaFsJoszn06fDQLmVkx8AhwhXNuW9D1SHLM7CTgY+fcoqBrkQYrAMYAf3TOlQKfAhpfm0XMrCO+F6gf0ANoY2ZfD7aq3KQQVtNaoHfU7V6oCTbrmFkLfAB70Dn3j6DrkXqZCJxsZqvwwwFCZvZAsCVJPa0F1jrnIi3QD+NDmWSP44D3nHMbnHP7gH8AEwKuKScphNW0EBhkZv3MrCV+IOLjAdck9WBmhh+Lssw5d1PQ9Uj9OOd+5Jzr5Zzri//5m+2c03/gWcQ59xGwxsyGhO/6DPBmgCVJ/b0PHG1mReHfqZ9BB1ekRUHQBWQS51yVmX0beBp/NMjdzrk3Ai5L6mcicA7wmpktCd/3Y+fczOBKEml2vgM8GP5ndiVwfsD1SD045140s4eBV/BHnC9Gs+enhWbMFxEREQmAuiNFREREAqAQJiIiIhIAhTARERGRACiEiYiIiARAIUxEREQkAAphIpL1zGy/mS2JWlI2Q7uZ9TWz11P1eiIiEZonTERywS7nXEnQRYiI1IdawkQkZ5nZKjP7jZm9FF4Ghu/vY2bPmtnS8OUR4fu7mdmjZvZqeImcqiXfzO40szfM7D9m1jq8/uVm9mb4dWYE9DZFJEsphIlILmgd0x15RtRj25xz44A/ADeH7/sDcL9zbhTwIHBr+P5bgbnOudH48x1GzpgxCLjNOTcC2AJ8OXz/NUBp+HUuTc9bE5FcpRnzRSTrmdkO51xxnPtXASHn3Mrwid0/cs51MrONQHfn3L7w/R865zqb2Qagl3NuT9Rr9AWecc4NCt++GmjhnPuVmT0F7AAeAx5zzu1I81sVkRyiljARyXUuwfVE68SzJ+r6fqrH054I3AYcBSwyM42zFZGkKYSJSK47I+ryv+HrC4Azw9fPBp4LX38WuAzAzPLNrF2iFzWzPKC3c24O8EOgA3BIa5yISCL6r01EckFrM1sSdfsp51xkmopCM3sR/0/nWeH7LgfuNrOrgA3A+eH7vwtMN7ML8S1elwEfJthmPvCAmbUHDPi9c25Lit6PiDQDGhMmIjkrPCaszDm3MehaRERiqTtSREREJABqCRMREREJgFrCRERERAKgECYiIiISAIUwERERkQAohImIiIgEQCFMREREJAAKYSIiIiIB+P/fvoHIXhw8iwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(filepath_or_buffer='./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "\n",
    "# Extract data from DataFrame\n",
    "epochs = data['epoch']\n",
    "train_loss = data['loss']\n",
    "val_loss = data['val_loss']\n",
    "\n",
    "# Plotting loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title(f'{target},{architecture}')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f353c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
