{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e87dd95-1e3c-4be9-a818-d388fceabb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 15:38:05.682730: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-12 15:38:05.682767: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-12 15:38:05.682808: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-12 15:38:05.692412: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-12 15:38:06.811285: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scott/Dropbox/IMAGINE Project/MSSI_Project\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow_hub as hub\n",
    "from keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# for figures\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import seaborn as sns\n",
    "\n",
    "# for the Grad-CAMs\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Working Directory on A4 Computer (GoPro and V2 data are on the A4 Computer)\n",
    "files = os.listdir()\n",
    "\n",
    "os.chdir(\"/home/scott/Dropbox/IMAGINE Project/MSSI_Project/\")\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "# This code allows GPU memory allocation to grow as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0df2768-b8d1-4a63-a59a-3809d48e0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "2.14.0\n",
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "#  Prints the Tensorflow, Keras versions, and number of GPUs\n",
    "print(tf.__version__)\n",
    "print(K.__version__)\n",
    "# print(\"TensorFlow Hub version:\", hub.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65cfbcfc-2915-4d30-91a6-65e547cc84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.19\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a893dc-398a-47bd-9d90-59ce2b1fa3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 12 15:38:18 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN Xp     On   | 00000000:05:00.0  On |                  N/A |\n",
      "| 23%   37C    P8    11W / 250W |    250MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN Xp     On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 23%   37C    P8    10W / 250W |      4MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN Xp     On   | 00000000:09:00.0 Off |                  N/A |\n",
      "| 23%   34C    P8    10W / 250W |      4MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA TITAN Xp     On   | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8     9W / 250W |      4MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1514      G   /usr/lib/xorg/Xorg                 14MiB |\n",
      "|    0   N/A  N/A      1665      G   /usr/bin/gnome-shell               64MiB |\n",
      "|    0   N/A  N/A      1929      G   /usr/lib/xorg/Xorg                 93MiB |\n",
      "|    0   N/A  N/A      2060      G   /usr/bin/gnome-shell               56MiB |\n",
      "|    0   N/A  N/A      2084      G   ...mviewer/tv_bin/TeamViewer       14MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd131a79-fe7f-43ef-ab57-b09fd1a635f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This compiled file incorporate all existing data with GoPro in training set only\n",
    "\n",
    "metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04252024.csv\", low_memory=False)\n",
    "# Train: 100% GoPro + 80% Imagine V2 and V3\n",
    "# Val: 10% Imagine V2 and V3\n",
    "# Tst: 10% Imagine V2 and V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d06a6b8c-a012-4feb-946c-6ce1cac5f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs in the entire DataFrame\n",
    "# print(metadata.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f4b93e-a252-4c16-977f-5be2f19e32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no NaNs in data\n",
    "# assert not np.any(np.isnan(metadata['ln_ufp_num_10s_ma_image_label_raw']))\n",
    "# assert not np.any(np.isnan(metadata[image_path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "971550d2-1878-4a28-a9b1-04aa77e54c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metadata['image_path'][200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae5e68c5-d373-4c4b-9c03-96f9df0db5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>image_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>ln_ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_num_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_image_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_spec_label_raw</th>\n",
       "      <th>ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>ufp_size_10s_ma_spec_label_quartile</th>\n",
       "      <th>ufp_size_10s_ma_image_label_quartile</th>\n",
       "      <th>image_extension</th>\n",
       "      <th>audio_extension</th>\n",
       "      <th>image_name</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>pair_pm25</th>\n",
       "      <th>set_V3ext</th>\n",
       "      <th>set</th>\n",
       "      <th>vsby_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-23T10:20:27Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.744668</td>\n",
       "      <td>9.744668</td>\n",
       "      <td>3.098740</td>\n",
       "      <td>3.098740</td>\n",
       "      <td>4.319752</td>\n",
       "      <td>4.319752</td>\n",
       "      <td>17063.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-23T10:20:28Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.710145</td>\n",
       "      <td>9.710145</td>\n",
       "      <td>3.119276</td>\n",
       "      <td>3.119276</td>\n",
       "      <td>4.309322</td>\n",
       "      <td>4.309322</td>\n",
       "      <td>16484.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-23T10:20:29Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.683153</td>\n",
       "      <td>9.683153</td>\n",
       "      <td>3.144583</td>\n",
       "      <td>3.144583</td>\n",
       "      <td>4.327702</td>\n",
       "      <td>4.327702</td>\n",
       "      <td>16045.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-23T10:20:30Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.583558</td>\n",
       "      <td>9.583558</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>4.320018</td>\n",
       "      <td>4.320018</td>\n",
       "      <td>14524.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-23T10:20:31Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.509259</td>\n",
       "      <td>9.509259</td>\n",
       "      <td>3.184698</td>\n",
       "      <td>3.184698</td>\n",
       "      <td>4.303119</td>\n",
       "      <td>4.303119</td>\n",
       "      <td>13484.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-23T10:20:32Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.479069</td>\n",
       "      <td>9.479069</td>\n",
       "      <td>3.197448</td>\n",
       "      <td>3.197448</td>\n",
       "      <td>4.277360</td>\n",
       "      <td>4.277360</td>\n",
       "      <td>13083.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-23T10:20:33Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.422544</td>\n",
       "      <td>9.422544</td>\n",
       "      <td>3.211650</td>\n",
       "      <td>3.211650</td>\n",
       "      <td>4.273606</td>\n",
       "      <td>4.273606</td>\n",
       "      <td>12364.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-04-23T10:20:34Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.399638</td>\n",
       "      <td>9.399638</td>\n",
       "      <td>3.223664</td>\n",
       "      <td>3.223664</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>12084.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-04-23T10:20:35Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.403107</td>\n",
       "      <td>9.403107</td>\n",
       "      <td>3.235536</td>\n",
       "      <td>3.235536</td>\n",
       "      <td>4.227709</td>\n",
       "      <td>4.227709</td>\n",
       "      <td>12126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-04-23T10:20:36Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.406976</td>\n",
       "      <td>9.406976</td>\n",
       "      <td>3.241029</td>\n",
       "      <td>3.241029</td>\n",
       "      <td>4.200804</td>\n",
       "      <td>4.200804</td>\n",
       "      <td>12173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime                                         image_path  \\\n",
       "0  2019-04-23T10:20:27Z  archived files no longer used/GoPro Model/data...   \n",
       "1  2019-04-23T10:20:28Z  archived files no longer used/GoPro Model/data...   \n",
       "2  2019-04-23T10:20:29Z  archived files no longer used/GoPro Model/data...   \n",
       "3  2019-04-23T10:20:30Z  archived files no longer used/GoPro Model/data...   \n",
       "4  2019-04-23T10:20:31Z  archived files no longer used/GoPro Model/data...   \n",
       "5  2019-04-23T10:20:32Z  archived files no longer used/GoPro Model/data...   \n",
       "6  2019-04-23T10:20:33Z  archived files no longer used/GoPro Model/data...   \n",
       "7  2019-04-23T10:20:34Z  archived files no longer used/GoPro Model/data...   \n",
       "8  2019-04-23T10:20:35Z  archived files no longer used/GoPro Model/data...   \n",
       "9  2019-04-23T10:20:36Z  archived files no longer used/GoPro Model/data...   \n",
       "\n",
       "                                          audio_path  \\\n",
       "0  archived files no longer used/GoPro Model/data...   \n",
       "1  archived files no longer used/GoPro Model/data...   \n",
       "2  archived files no longer used/GoPro Model/data...   \n",
       "3  archived files no longer used/GoPro Model/data...   \n",
       "4  archived files no longer used/GoPro Model/data...   \n",
       "5  archived files no longer used/GoPro Model/data...   \n",
       "6  archived files no longer used/GoPro Model/data...   \n",
       "7  archived files no longer used/GoPro Model/data...   \n",
       "8  archived files no longer used/GoPro Model/data...   \n",
       "9  archived files no longer used/GoPro Model/data...   \n",
       "\n",
       "   ln_ufp_num_10s_ma_image_label_raw  ln_ufp_num_10s_ma_spec_label_raw  \\\n",
       "0                           9.744668                          9.744668   \n",
       "1                           9.710145                          9.710145   \n",
       "2                           9.683153                          9.683153   \n",
       "3                           9.583558                          9.583558   \n",
       "4                           9.509259                          9.509259   \n",
       "5                           9.479069                          9.479069   \n",
       "6                           9.422544                          9.422544   \n",
       "7                           9.399638                          9.399638   \n",
       "8                           9.403107                          9.403107   \n",
       "9                           9.406976                          9.406976   \n",
       "\n",
       "   ln_ufp_size_10s_ma_image_label_raw  ln_ufp_size_10s_ma_spec_label_raw  \\\n",
       "0                            3.098740                           3.098740   \n",
       "1                            3.119276                           3.119276   \n",
       "2                            3.144583                           3.144583   \n",
       "3                            3.167583                           3.167583   \n",
       "4                            3.184698                           3.184698   \n",
       "5                            3.197448                           3.197448   \n",
       "6                            3.211650                           3.211650   \n",
       "7                            3.223664                           3.223664   \n",
       "8                            3.235536                           3.235536   \n",
       "9                            3.241029                           3.241029   \n",
       "\n",
       "   ln_noise_10s_ma_image_label_raw  ln_noise_10s_ma_spec_label_raw  \\\n",
       "0                         4.319752                        4.319752   \n",
       "1                         4.309322                        4.309322   \n",
       "2                         4.327702                        4.327702   \n",
       "3                         4.320018                        4.320018   \n",
       "4                         4.303119                        4.303119   \n",
       "5                         4.277360                        4.277360   \n",
       "6                         4.273606                        4.273606   \n",
       "7                         4.260000                        4.260000   \n",
       "8                         4.227709                        4.227709   \n",
       "9                         4.200804                        4.200804   \n",
       "\n",
       "   ufp_num_10s_ma_image_label_raw  ...  ufp_size_10s_ma_spec_label_quartile  \\\n",
       "0                         17063.0  ...                                  NaN   \n",
       "1                         16484.0  ...                                  NaN   \n",
       "2                         16045.0  ...                                  NaN   \n",
       "3                         14524.0  ...                                  NaN   \n",
       "4                         13484.0  ...                                  NaN   \n",
       "5                         13083.0  ...                                  NaN   \n",
       "6                         12364.0  ...                                  NaN   \n",
       "7                         12084.0  ...                                  NaN   \n",
       "8                         12126.0  ...                                  NaN   \n",
       "9                         12173.0  ...                                  NaN   \n",
       "\n",
       "   ufp_size_10s_ma_image_label_quartile  image_extension  audio_extension  \\\n",
       "0                                   NaN              NaN              NaN   \n",
       "1                                   NaN              NaN              NaN   \n",
       "2                                   NaN              NaN              NaN   \n",
       "3                                   NaN              NaN              NaN   \n",
       "4                                   NaN              NaN              NaN   \n",
       "5                                   NaN              NaN              NaN   \n",
       "6                                   NaN              NaN              NaN   \n",
       "7                                   NaN              NaN              NaN   \n",
       "8                                   NaN              NaN              NaN   \n",
       "9                                   NaN              NaN              NaN   \n",
       "\n",
       "   image_name  audio_name  pair_pm25  set_V3ext  set  vsby_nm  \n",
       "0         NaN         NaN        NaN        trn  trn     30.0  \n",
       "1         NaN         NaN        NaN        trn  trn     30.0  \n",
       "2         NaN         NaN        NaN        trn  trn     30.0  \n",
       "3         NaN         NaN        NaN        trn  trn     30.0  \n",
       "4         NaN         NaN        NaN        trn  trn     30.0  \n",
       "5         NaN         NaN        NaN        trn  trn     30.0  \n",
       "6         NaN         NaN        NaN        trn  trn     30.0  \n",
       "7         NaN         NaN        NaN        trn  trn     30.0  \n",
       "8         NaN         NaN        NaN        trn  trn     30.0  \n",
       "9         NaN         NaN        NaN        trn  trn     30.0  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at data\n",
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa50759a-cd27-44ce-b977-d97010454395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set\n",
       "trn    345680\n",
       "val     22407\n",
       "tst     22223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much data in trn, val, tst sets for metadata_random_split\n",
    "\n",
    "metadata.set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0500d9f9-9670-4575-8866-0e3b61423014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What input are you using: images, or spectrograms?  spectrograms\n"
     ]
    }
   ],
   "source": [
    "#Select input file type (this tells python where to look for the file paths)\n",
    "file = input(\"What input are you using: images, or spectrograms? \")\n",
    "\n",
    "if file == 'images':\n",
    "    file = 'image_path'\n",
    "else:\n",
    "  if file == 'spectrograms':\n",
    "      file = 'audio_path'\n",
    "  else:\n",
    "    print('!!!TYPO in input_data name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebcd3152-4961-4dd8-8899-592ba89e5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Initial Learning Rate\n",
    "initial_learning_rate = 1e-4\n",
    "meta_data_name = \"gp_v2_v3_Training_Only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f18a648a-0e01-4748-bcfb-d275c186f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What architecture do you want to use: ConvNeXT_linear_AdamW_Base, ConvNeXT_linear_AdamW_Large, ConvNeXt_Tiny_linear_AdamW, ResNet50_AdamW_Nadam ? ConvNeXT_linear_AdamW_Base\n"
     ]
    }
   ],
   "source": [
    "# Model architectures\n",
    "architecture = input(\"What architecture do you want to use: ConvNeXT_linear_AdamW_Base, ConvNeXT_linear_AdamW_Large, ConvNeXt_Tiny_linear_AdamW, ResNet50_AdamW_Nadam ?\")\n",
    "from tensorflow.keras import backend as Kb\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    loss = Kb.mean(Kb.square(y_true - y_pred), axis=-1)\n",
    "    tf.print(\"y_true:\", y_true)\n",
    "    tf.print(\"y_pred:\", y_pred)\n",
    "    tf.print(\"loss:\", loss)\n",
    "    return loss\n",
    "    \n",
    "if architecture == 'ConvNeXT_linear_AdamW_Base':\n",
    "    architecture_preprocessing = K.applications.convnext.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ConvNeXtBase(model_name=\"convnext_base\",include_top=False, weights=\"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(model_output) \n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.AdamW(learning_rate=initial_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "elif architecture == 'ConvNeXT_linear_AdamW_Large':\n",
    "    architecture_preprocessing = K.applications.convnext.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ConvNeXtLarge(include_top=False, weights=\"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(model_output)\n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.AdamW(learning_rate=initial_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "elif architecture == 'ConvNeXt_Tiny_AdamW_Nadam':\n",
    "    architecture_preprocessing = K.applications.convnext.preprocess_input\n",
    "\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ConvNeXtTiny(include_top=False, weights=\"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(model_output)\n",
    "    \n",
    "        # Learning rate schedule\n",
    "        initial_learning_rate = 1e-5\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "            initial_learning_rate=initial_learning_rate,\n",
    "            decay_steps=10000,\n",
    "            alpha=0.0\n",
    "        )\n",
    "        optimizer = K.optimizers.AdamW(learning_rate=lr_schedule, clipnorm=1.0)\n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "elif architecture == 'ResNet50_AdamW_Nadam':\n",
    "    architecture_preprocessing = K.applications.resnet50.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ResNet50(include_top=False, weights= \"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units= 1, activation='linear')(model_output) \n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.AdamW(learning_rate = initial_learning_rate),\n",
    "            loss = custom_mse,\n",
    "            metrics = ['mae']\n",
    "        )\n",
    "        return model\n",
    "                        \n",
    "else:\n",
    "    print('!!!TYPO in architecture name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c001b37-cddb-4b49-ba75-6b620359a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scott/Dropbox/IMAGINE Project/MSSI_Project\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ? ln_noise_10s_ma_spec_label_raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 345680 validated image filenames.\n",
      "Found 22407 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Select Exposure to be modelled\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "target = input(\"What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ?\")                  \n",
    "\n",
    "if target == 'ln_noise_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # file = image_path or audio_path\n",
    "                                                y_col= target,  # taget = exposure to be modelled\n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "elif target == 'ln_noise_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_num_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    \n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "elif target == 'ln_ufp_num_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')    \n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_image_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    " \n",
    "    \n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_spec_label_raw':\n",
    "\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                     horizontal_flip=True,\n",
    "                                                     vertical_flip = False)\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='trn', [target, file]].reset_index(drop=True),  \n",
    "                                                x_col= file, # \n",
    "                                                y_col= target,  # \n",
    "                                                class_mode = 'raw', \n",
    "                                                target_size=(256, 256), # all of our images will be resized to 256 x 256\n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['set']=='val', [target, file]].reset_index(drop=True),\n",
    "                                                     x_col= file,\n",
    "                                                     y_col=target,\n",
    "                                                     class_mode='raw',\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "else:\n",
    "    print('!!!TYPO in exposure name') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a14d02-dda0-4c3e-8888-4623d53726ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve a batch from the train generator\n",
    "# x_batch, y_batch = next(train_generator)\n",
    "\n",
    "# # Print the shape of the batch\n",
    "# print(f\"x_batch shape: {x_batch.shape}, y_batch shape: {y_batch.shape}\")\n",
    "\n",
    "# # Print and visualize some samples from the batch\n",
    "# num_samples_to_display = 5  # Number of samples to display\n",
    "\n",
    "# for i in range(num_samples_to_display):\n",
    "#     plt.imshow(x_batch[i].astype('uint8'))  # Convert to uint8 if necessary\n",
    "#     plt.title(f\"Label: {y_batch[i]}\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bbd4529-537f-4880-a0a9-e8889d7b28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch from the validate generator\n",
    "# x_val_batch, y_val_batch = next(validate_generator)\n",
    "\n",
    "# # Print the shape of the batch\n",
    "# print(f\"x_val_batch shape: {x_val_batch.shape}, y_val_batch shape: {y_val_batch.shape}\")\n",
    "\n",
    "# # Print and visualize some samples from the batch\n",
    "# num_samples_to_display = 5  # Number of samples to display\n",
    "\n",
    "# for i in range(num_samples_to_display):\n",
    "#     plt.imshow(x_val_batch[i].astype('uint8'))  # Convert to uint8 if necessary\n",
    "#     plt.title(f\"Label: {y_val_batch[i]}\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75aa593-83aa-49c1-a371-7f6aa961e0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "# Check a batch from the train generator\n",
    "# x_batch, y_batch = next(train_generator)\n",
    "# print(np.isnan(x_batch).any(), np.isnan(y_batch).any())\n",
    "\n",
    "# # Check a batch from the validate generator\n",
    "# x_batch, y_batch = next(validate_generator)\n",
    "# print(np.isnan(x_batch).any(), np.isnan(y_batch).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ce605-af4c-4578-b8a8-7778294a9856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 15:39:55.958979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11162 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2024-06-12 15:39:55.959550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11409 MB memory:  -> device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:06:00.0, compute capability: 6.1\n",
      "2024-06-12 15:39:55.960026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11409 MB memory:  -> device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "2024-06-12 15:39:55.960492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 11410 MB memory:  -> device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:0a:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "INFO:tensorflow:Collective all_reduce tensors: 344 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Collective all_reduce tensors: 344 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 15:43:41.498666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-06-12 15:43:42.221571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-06-12 15:43:42.407592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-06-12 15:43:42.756309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-06-12 15:43:43.448315: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f33a7437670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-12 15:43:43.448348: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-06-12 15:43:43.448356: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-06-12 15:43:43.448363: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-06-12 15:43:43.448368: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-06-12 15:43:43.996892: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-12 15:43:50.202505: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-12 15:43:50.204063: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_3_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-12 15:43:50.205717: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-12 15:43:50.206115: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_2_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-12 15:43:54.956468: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5402/5402 [==============================] - ETA: 0s - loss: 0.0123 - mae: 0.0690INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_noise_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_noise_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5402/5402 [==============================] - 5218s 918ms/step - loss: 0.0123 - mae: 0.0690 - val_loss: 0.0138 - val_mae: 0.1016 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "5402/5402 [==============================] - 4970s 920ms/step - loss: 0.0054 - mae: 0.0558 - val_loss: 0.0045 - val_mae: 0.0486 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "2998/5402 [===============>..............] - ETA: 34:58 - loss: 0.0038 - mae: 0.0460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5402/5402 [==============================] - ETA: 0s - loss: 0.0036 - mae: 0.0444INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_noise_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_noise_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5402/5402 [==============================] - 4971s 920ms/step - loss: 0.0036 - mae: 0.0444 - val_loss: 0.0041 - val_mae: 0.0452 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "3097/5402 [================>.............] - ETA: 33:33 - loss: 0.0027 - mae: 0.0380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5385/5402 [============================>.] - ETA: 14s - loss: 0.0027 - mae: 0.0373INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_noise_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/ln_noise_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5402/5402 [==============================] - 4973s 920ms/step - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0041 - val_mae: 0.0456 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "2869/5402 [==============>...............] - ETA: 36:48 - loss: 0.0022 - mae: 0.0334"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model = get_compiled_model()\n",
    "    \n",
    "\n",
    "#Fit Model\n",
    "model.fit(train_generator,\n",
    "          validation_data=validate_generator,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=int(np.ceil(train_generator.samples/train_generator.batch_size)),\n",
    "          validation_steps=int(np.ceil(validate_generator.samples/validate_generator.batch_size)),\n",
    "          callbacks=[csv_logger, \n",
    "                     reduce_lr_on_plateau, \n",
    "                     model_checkpoint,\n",
    "                     early_stopping] \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2d047f-3b3f-4031-9b9d-59231fb685d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_epoch: 6\n",
      "best_val_loss: 0.0040341755375266\n",
      "best_val_mae: 0.0478566065430641\n"
     ]
    }
   ],
   "source": [
    "#Identify Best Epoch\n",
    "res = pd.read_csv(filepath_or_buffer='./rishabh_model_files/logs/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "res = res.sort_values('val_loss', ascending=True).reset_index(drop=True)\n",
    "best_epoch = res.epoch[0]\n",
    "best_val_loss = res.val_loss[0]\n",
    "best_val_mae = res.val_mae[0]\n",
    "print(\"best_epoch:\", best_epoch)\n",
    "print(\"best_val_loss:\", best_val_loss)\n",
    "print(\"best_val_mae:\", best_val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52e231a4-20ef-4490-a214-5fc2f19c4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test code with ResNet50 and CIFAR10 dataset\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers, models\n",
    "# from tensorflow.keras.applications import ResNet50\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Load CIFAR-10 dataset\n",
    "# metad = keras.datasets.cifar10.load_data()\n",
    "# (x_train, y_train), (x_test, y_test) = metad\n",
    "# print(x_train)\n",
    "\n",
    "# # Normalize the data\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# # Convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, 10)\n",
    "# y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# # Data augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=False,\n",
    "#     samplewise_center=False,\n",
    "#     featurewise_std_normalization=False,\n",
    "#     samplewise_std_normalization=False,\n",
    "#     zca_whitening=False,\n",
    "#     rotation_range=15,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=False\n",
    "# )\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# def create_resnet50_model():\n",
    "#     model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "#     conv_base = K.applications.ResNet50(include_top=False, weights= \"imagenet\", input_tensor=model_input)\n",
    "#     model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "#     model_output = K.layers.Dense(units= 1, activation='linear')(model_output) \n",
    "#     model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "#     model.compile(\n",
    "#         optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "#         loss = 'mse',\n",
    "#         metrics = ['mae']\n",
    "#     )\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# model = create_resnet50_model()\n",
    "\n",
    "# # Define callbacks\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"resnet50_cifar10.h5\", save_best_only=True),\n",
    "#     keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1),\n",
    "#     keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# ]\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
    "#           validation_data=(x_test, y_test),\n",
    "#           epochs=50,\n",
    "#           callbacks=callbacks)\n",
    "\n",
    "# # Evaluate the model\n",
    "# test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "# print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1207c5a-042f-4c01-b668-b28a9431d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # experiment with no data augmentation\n",
    "# # experimented with 'relu' activation\n",
    "# # experimented with loer learning rae (1e-7)\n",
    "# from tensorflow.keras import backend as Kb\n",
    "\n",
    "# architecture = 'ResNet50_linear_Nadam'\n",
    "# target = 'ln_noise_10s_ma_image_label_raw'\n",
    "# initial_learning_rate = 1e-4\n",
    "# meta_data_name = \"gp_v2_v3_Training_Only\"\n",
    "\n",
    "# def custom_mse(y_true, y_pred):\n",
    "#     loss = Kb.mean(Kb.square(y_true - y_pred), axis=-1)\n",
    "#     tf.print(\"y_true:\", y_true)\n",
    "#     tf.print(\"y_pred:\", y_pred)\n",
    "#     tf.print(\"loss:\", loss)\n",
    "#     return loss\n",
    "\n",
    "# # architecture_preprocessing = K.applications.resnet50.preprocess_input\n",
    "# architecture_preprocessing = tf.keras.applications.resnet.preprocess_input\n",
    "\n",
    "# # Initialize ImageDataGenerator without augmentation\n",
    "# generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing)\n",
    "\n",
    "# # Create training and validation generators\n",
    "# train_generator = generator.flow_from_dataframe(\n",
    "#     dataframe=metadata.loc[metadata['set'] == 'trn', [target, file]].reset_index(drop=True),\n",
    "#     x_col=file,  # file = image_path or audio_path\n",
    "#     y_col=target,  # target = exposure to be modeled\n",
    "#     class_mode='raw',\n",
    "#     target_size=(256, 256),  # all of our images will be resized to 256 x 256\n",
    "#     color_mode='rgb',\n",
    "#     batch_size=64,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "# validate_generator = generator.flow_from_dataframe(\n",
    "#     dataframe=metadata.loc[metadata['set'] == 'val', [target, file]].reset_index(drop=True),\n",
    "#     x_col=file,\n",
    "#     y_col=target,\n",
    "#     class_mode='raw',\n",
    "#     target_size=(256, 256),\n",
    "#     color_mode='rgb',\n",
    "#     batch_size=64,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "# # Define callbacks\n",
    "# csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/' + target + ',' + architecture + ',' + file + ',' + meta_data_name + '_Combined_IMAGINE_goproUFP_V2_V3_04252024.csv')\n",
    "# model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/' + target + ',' + architecture + ',' + file + ',' + meta_data_name + '_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf', monitor='val_loss', mode='auto', save_weights_only=False, save_best_only=True)\n",
    "# reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "# early_stopping = K.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# def get_compiled_model():\n",
    "#     model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "#     conv_base = K.applications.ResNet50(include_top=False, weights= \"imagenet\", input_tensor=model_input)\n",
    "#     model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "#     # model_output = K.layers.BatchNormalization()(model_output)  # Add BatchNormalization layer\n",
    "#     model_output = K.layers.Dense(units= 1, activation='linear')(model_output) \n",
    "#     model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "#     model.compile(\n",
    "#         optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "#         loss = 'mse',\n",
    "#         metrics = ['mae']\n",
    "#     )\n",
    "#     return model\n",
    "\n",
    "# # Create a MirroredStrategy for distributed training\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# # Open a strategy scope and compile the model\n",
    "# with strategy.scope():\n",
    "#     model = get_compiled_model()\n",
    "\n",
    "# # Check for NaNs in input data batches\n",
    "# x_batch, y_batch = next(train_generator)\n",
    "# print(\"NaNs in training batch:\", np.isnan(x_batch).any(), np.isnan(y_batch).any())\n",
    "\n",
    "# x_val_batch, y_val_batch = next(validate_generator)\n",
    "# print(\"NaNs in validation batch:\", np.isnan(x_val_batch).any(), np.isnan(y_val_batch).any())\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(\n",
    "#     train_generator,\n",
    "#     validation_data=validate_generator,\n",
    "#     epochs=10,\n",
    "#     callbacks=[csv_logger, reduce_lr_on_plateau, model_checkpoint, early_stopping]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24818264-c0ba-4bc3-97cb-1f70f44e5299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagine-env",
   "language": "python",
   "name": "imagine-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
