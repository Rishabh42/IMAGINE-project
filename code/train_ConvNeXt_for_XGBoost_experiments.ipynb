{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e87dd95-1e3c-4be9-a818-d388fceabb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scott/Dropbox/IMAGINE Project/MSSI_Project\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow_hub as hub\n",
    "from keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# for figures\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import seaborn as sns\n",
    "\n",
    "# for the Grad-CAMs\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Working Directory on A4 Computer (GoPro and V2 data are on the A4 Computer)\n",
    "files = os.listdir()\n",
    "\n",
    "os.chdir(\"/home/scott/Dropbox/IMAGINE Project/MSSI_Project/\")\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "# This code allows GPU memory allocation to grow as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0df2768-b8d1-4a63-a59a-3809d48e0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "2.14.0\n",
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "#  Prints the Tensorflow, Keras versions, and number of GPUs\n",
    "print(tf.__version__)\n",
    "print(K.__version__)\n",
    "# print(\"TensorFlow Hub version:\", hub.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65cfbcfc-2915-4d30-91a6-65e547cc84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.19\n",
      "cuDNN version: 8\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())\n",
    "print(\"cuDNN version:\", tf.sysconfig.get_build_info()['cudnn_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02a893dc-398a-47bd-9d90-59ce2b1fa3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 11 00:58:38 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN Xp     On   | 00000000:05:00.0  On |                  N/A |\n",
      "| 23%   37C    P8    18W / 250W |  12022MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN Xp     On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8     9W / 250W |  12004MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN Xp     On   | 00000000:09:00.0 Off |                  N/A |\n",
      "| 23%   31C    P8     9W / 250W |  12022MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA TITAN Xp     On   | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8     9W / 250W |  12004MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1514      G   /usr/lib/xorg/Xorg                 14MiB |\n",
      "|    0   N/A  N/A      1665      G   /usr/bin/gnome-shell               64MiB |\n",
      "|    0   N/A  N/A      1929      G   /usr/lib/xorg/Xorg                 91MiB |\n",
      "|    0   N/A  N/A      2060      G   /usr/bin/gnome-shell               56MiB |\n",
      "|    0   N/A  N/A      2084      G   ...mviewer/tv_bin/TeamViewer       14MiB |\n",
      "|    0   N/A  N/A      2941      C   ...s/imagine-env/bin/python3    11774MiB |\n",
      "|    1   N/A  N/A      2941      C   ...s/imagine-env/bin/python3    12000MiB |\n",
      "|    2   N/A  N/A      2941      C   ...s/imagine-env/bin/python3    12018MiB |\n",
      "|    3   N/A  N/A      2941      C   ...s/imagine-env/bin/python3    12000MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "755ca2bc-20d0-4612-b29c-38238224c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3666 GiB\n",
      "Used: 994 GiB\n",
      "Free: 2485 GiB\n"
     ]
    }
   ],
   "source": [
    "# Ensure there's enough space\n",
    "def check_disk_space():\n",
    "    total, used, free = shutil.disk_usage(\"/\")\n",
    "    print(f\"Total: {total // (2**30)} GiB\")\n",
    "    print(f\"Used: {used // (2**30)} GiB\")\n",
    "    print(f\"Free: {free // (2**30)} GiB\")\n",
    "    return free\n",
    "\n",
    "free_space = check_disk_space()\n",
    "if free_space < (1 * 2**30):  # Check if free space is less than 1 GiB\n",
    "    print(\"Warning: Low disk space. Consider freeing up some space.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd131a79-fe7f-43ef-ab57-b09fd1a635f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This compiled file incorporate all existing data with GoPro in training set only\n",
    "\n",
    "metadata = pd.read_csv(\"compiled data/metadata_goproUFP_V2_V3_04252024.csv\", low_memory=False)\n",
    "# Train: 100% GoPro + 80% Imagine V2 and V3\n",
    "# Val: 10% Imagine V2 and V3\n",
    "# Tst: 10% Imagine V2 and V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06a6b8c-a012-4feb-946c-6ce1cac5f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs in the entire DataFrame\n",
    "# print(metadata.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f4b93e-a252-4c16-977f-5be2f19e32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no NaNs in data\n",
    "# assert not np.any(np.isnan(metadata['ln_ufp_num_10s_ma_image_label_raw']))\n",
    "# assert not np.any(np.isnan(metadata[image_path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "971550d2-1878-4a28-a9b1-04aa77e54c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metadata['image_path'][200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae5e68c5-d373-4c4b-9c03-96f9df0db5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>image_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>ln_ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_num_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_image_label_raw</th>\n",
       "      <th>ln_ufp_size_10s_ma_spec_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_image_label_raw</th>\n",
       "      <th>ln_noise_10s_ma_spec_label_raw</th>\n",
       "      <th>ufp_num_10s_ma_image_label_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>ufp_size_10s_ma_spec_label_quartile</th>\n",
       "      <th>ufp_size_10s_ma_image_label_quartile</th>\n",
       "      <th>image_extension</th>\n",
       "      <th>audio_extension</th>\n",
       "      <th>image_name</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>pair_pm25</th>\n",
       "      <th>set_V3ext</th>\n",
       "      <th>set</th>\n",
       "      <th>vsby_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-23T10:20:27Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.744668</td>\n",
       "      <td>9.744668</td>\n",
       "      <td>3.098740</td>\n",
       "      <td>3.098740</td>\n",
       "      <td>4.319752</td>\n",
       "      <td>4.319752</td>\n",
       "      <td>17063.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-23T10:20:28Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.710145</td>\n",
       "      <td>9.710145</td>\n",
       "      <td>3.119276</td>\n",
       "      <td>3.119276</td>\n",
       "      <td>4.309322</td>\n",
       "      <td>4.309322</td>\n",
       "      <td>16484.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-23T10:20:29Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.683153</td>\n",
       "      <td>9.683153</td>\n",
       "      <td>3.144583</td>\n",
       "      <td>3.144583</td>\n",
       "      <td>4.327702</td>\n",
       "      <td>4.327702</td>\n",
       "      <td>16045.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-23T10:20:30Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.583558</td>\n",
       "      <td>9.583558</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>4.320018</td>\n",
       "      <td>4.320018</td>\n",
       "      <td>14524.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-23T10:20:31Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.509259</td>\n",
       "      <td>9.509259</td>\n",
       "      <td>3.184698</td>\n",
       "      <td>3.184698</td>\n",
       "      <td>4.303119</td>\n",
       "      <td>4.303119</td>\n",
       "      <td>13484.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-23T10:20:32Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.479069</td>\n",
       "      <td>9.479069</td>\n",
       "      <td>3.197448</td>\n",
       "      <td>3.197448</td>\n",
       "      <td>4.277360</td>\n",
       "      <td>4.277360</td>\n",
       "      <td>13083.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-23T10:20:33Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.422544</td>\n",
       "      <td>9.422544</td>\n",
       "      <td>3.211650</td>\n",
       "      <td>3.211650</td>\n",
       "      <td>4.273606</td>\n",
       "      <td>4.273606</td>\n",
       "      <td>12364.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-04-23T10:20:34Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.399638</td>\n",
       "      <td>9.399638</td>\n",
       "      <td>3.223664</td>\n",
       "      <td>3.223664</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>12084.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-04-23T10:20:35Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.403107</td>\n",
       "      <td>9.403107</td>\n",
       "      <td>3.235536</td>\n",
       "      <td>3.235536</td>\n",
       "      <td>4.227709</td>\n",
       "      <td>4.227709</td>\n",
       "      <td>12126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-04-23T10:20:36Z</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>archived files no longer used/GoPro Model/data...</td>\n",
       "      <td>9.406976</td>\n",
       "      <td>9.406976</td>\n",
       "      <td>3.241029</td>\n",
       "      <td>3.241029</td>\n",
       "      <td>4.200804</td>\n",
       "      <td>4.200804</td>\n",
       "      <td>12173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trn</td>\n",
       "      <td>trn</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime                                         image_path  \\\n",
       "0  2019-04-23T10:20:27Z  archived files no longer used/GoPro Model/data...   \n",
       "1  2019-04-23T10:20:28Z  archived files no longer used/GoPro Model/data...   \n",
       "2  2019-04-23T10:20:29Z  archived files no longer used/GoPro Model/data...   \n",
       "3  2019-04-23T10:20:30Z  archived files no longer used/GoPro Model/data...   \n",
       "4  2019-04-23T10:20:31Z  archived files no longer used/GoPro Model/data...   \n",
       "5  2019-04-23T10:20:32Z  archived files no longer used/GoPro Model/data...   \n",
       "6  2019-04-23T10:20:33Z  archived files no longer used/GoPro Model/data...   \n",
       "7  2019-04-23T10:20:34Z  archived files no longer used/GoPro Model/data...   \n",
       "8  2019-04-23T10:20:35Z  archived files no longer used/GoPro Model/data...   \n",
       "9  2019-04-23T10:20:36Z  archived files no longer used/GoPro Model/data...   \n",
       "\n",
       "                                          audio_path  \\\n",
       "0  archived files no longer used/GoPro Model/data...   \n",
       "1  archived files no longer used/GoPro Model/data...   \n",
       "2  archived files no longer used/GoPro Model/data...   \n",
       "3  archived files no longer used/GoPro Model/data...   \n",
       "4  archived files no longer used/GoPro Model/data...   \n",
       "5  archived files no longer used/GoPro Model/data...   \n",
       "6  archived files no longer used/GoPro Model/data...   \n",
       "7  archived files no longer used/GoPro Model/data...   \n",
       "8  archived files no longer used/GoPro Model/data...   \n",
       "9  archived files no longer used/GoPro Model/data...   \n",
       "\n",
       "   ln_ufp_num_10s_ma_image_label_raw  ln_ufp_num_10s_ma_spec_label_raw  \\\n",
       "0                           9.744668                          9.744668   \n",
       "1                           9.710145                          9.710145   \n",
       "2                           9.683153                          9.683153   \n",
       "3                           9.583558                          9.583558   \n",
       "4                           9.509259                          9.509259   \n",
       "5                           9.479069                          9.479069   \n",
       "6                           9.422544                          9.422544   \n",
       "7                           9.399638                          9.399638   \n",
       "8                           9.403107                          9.403107   \n",
       "9                           9.406976                          9.406976   \n",
       "\n",
       "   ln_ufp_size_10s_ma_image_label_raw  ln_ufp_size_10s_ma_spec_label_raw  \\\n",
       "0                            3.098740                           3.098740   \n",
       "1                            3.119276                           3.119276   \n",
       "2                            3.144583                           3.144583   \n",
       "3                            3.167583                           3.167583   \n",
       "4                            3.184698                           3.184698   \n",
       "5                            3.197448                           3.197448   \n",
       "6                            3.211650                           3.211650   \n",
       "7                            3.223664                           3.223664   \n",
       "8                            3.235536                           3.235536   \n",
       "9                            3.241029                           3.241029   \n",
       "\n",
       "   ln_noise_10s_ma_image_label_raw  ln_noise_10s_ma_spec_label_raw  \\\n",
       "0                         4.319752                        4.319752   \n",
       "1                         4.309322                        4.309322   \n",
       "2                         4.327702                        4.327702   \n",
       "3                         4.320018                        4.320018   \n",
       "4                         4.303119                        4.303119   \n",
       "5                         4.277360                        4.277360   \n",
       "6                         4.273606                        4.273606   \n",
       "7                         4.260000                        4.260000   \n",
       "8                         4.227709                        4.227709   \n",
       "9                         4.200804                        4.200804   \n",
       "\n",
       "   ufp_num_10s_ma_image_label_raw  ...  ufp_size_10s_ma_spec_label_quartile  \\\n",
       "0                         17063.0  ...                                  NaN   \n",
       "1                         16484.0  ...                                  NaN   \n",
       "2                         16045.0  ...                                  NaN   \n",
       "3                         14524.0  ...                                  NaN   \n",
       "4                         13484.0  ...                                  NaN   \n",
       "5                         13083.0  ...                                  NaN   \n",
       "6                         12364.0  ...                                  NaN   \n",
       "7                         12084.0  ...                                  NaN   \n",
       "8                         12126.0  ...                                  NaN   \n",
       "9                         12173.0  ...                                  NaN   \n",
       "\n",
       "   ufp_size_10s_ma_image_label_quartile  image_extension  audio_extension  \\\n",
       "0                                   NaN              NaN              NaN   \n",
       "1                                   NaN              NaN              NaN   \n",
       "2                                   NaN              NaN              NaN   \n",
       "3                                   NaN              NaN              NaN   \n",
       "4                                   NaN              NaN              NaN   \n",
       "5                                   NaN              NaN              NaN   \n",
       "6                                   NaN              NaN              NaN   \n",
       "7                                   NaN              NaN              NaN   \n",
       "8                                   NaN              NaN              NaN   \n",
       "9                                   NaN              NaN              NaN   \n",
       "\n",
       "   image_name  audio_name  pair_pm25  set_V3ext  set  vsby_nm  \n",
       "0         NaN         NaN        NaN        trn  trn     30.0  \n",
       "1         NaN         NaN        NaN        trn  trn     30.0  \n",
       "2         NaN         NaN        NaN        trn  trn     30.0  \n",
       "3         NaN         NaN        NaN        trn  trn     30.0  \n",
       "4         NaN         NaN        NaN        trn  trn     30.0  \n",
       "5         NaN         NaN        NaN        trn  trn     30.0  \n",
       "6         NaN         NaN        NaN        trn  trn     30.0  \n",
       "7         NaN         NaN        NaN        trn  trn     30.0  \n",
       "8         NaN         NaN        NaN        trn  trn     30.0  \n",
       "9         NaN         NaN        NaN        trn  trn     30.0  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at data\n",
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa50759a-cd27-44ce-b977-d97010454395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set\n",
       "trn    345680\n",
       "val     22407\n",
       "tst     22223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much data in trn, val, tst sets for metadata_random_split\n",
    "\n",
    "metadata.set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684bfb1-80ab-4e92-9844-ce08f19d86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: compare total image and audio data fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0500d9f9-9670-4575-8866-0e3b61423014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What input are you using: images, or spectrograms?  images\n"
     ]
    }
   ],
   "source": [
    "#Select input file type (this tells python where to look for the file paths)\n",
    "file = input(\"What input are you using: images, or spectrograms? \")\n",
    "\n",
    "if file == 'images':\n",
    "    file = 'image_path'\n",
    "else:\n",
    "  if file == 'spectrograms':\n",
    "      file = 'audio_path'\n",
    "  else:\n",
    "    print('!!!TYPO in input_data name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebcd3152-4961-4dd8-8899-592ba89e5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Initial Learning Rate\n",
    "initial_learning_rate = 1e-4\n",
    "meta_data_name = \"gp_v2_v3_Training_Only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f18a648a-0e01-4748-bcfb-d275c186f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What architecture do you want to use: ConvNeXT_linear_AdamW_Base, ConvNeXT_linear_AdamW_Large, ConvNeXt_Tiny_linear_AdamW, ResNet50_AdamW_Nadam, ConvNeXT_linear_AdamW_Base_L2_Dropout ? ConvNeXT_linear_AdamW_Base_L2_Dropout\n"
     ]
    }
   ],
   "source": [
    "# Model architectures\n",
    "architecture = input(\"What architecture do you want to use: ConvNeXT_linear_AdamW_Base, ConvNeXT_linear_AdamW_Large, ConvNeXt_Tiny_linear_AdamW, ResNet50_AdamW_Nadam, ConvNeXT_linear_AdamW_Base_L2_Dropout ?\")\n",
    "from tensorflow.keras import backend as Kb\n",
    "\n",
    "# Define global variables for dropout rate and L2 regularization strength\n",
    "global_dropout_rate = 0.3\n",
    "global_l2_regularization = 1e-4\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    loss = Kb.mean(Kb.square(y_true - y_pred), axis=-1)\n",
    "    tf.print(\"y_true:\", y_true)\n",
    "    tf.print(\"y_pred:\", y_pred)\n",
    "    tf.print(\"loss:\", loss)\n",
    "    return loss\n",
    "    \n",
    "if architecture == 'ConvNeXT_linear_AdamW_Base':\n",
    "    architecture_preprocessing = K.applications.convnext.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ConvNeXtBase(model_name=\"convnext_base\",include_top=False, weights=\"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(model_output) \n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.AdamW(learning_rate=initial_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "elif architecture == 'ConvNeXT_linear_AdamW_Base_L2_Dropout':\n",
    "    # Preprocessing function\n",
    "    architecture_preprocessing = K.applications.convnext.preprocess_input\n",
    "\n",
    "    # Define the model function\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "    \n",
    "        # Load ConvNeXt base model\n",
    "        conv_base = K.applications.ConvNeXtBase(\n",
    "            model_name=\"convnext_base\",\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=model_input\n",
    "        )\n",
    "    \n",
    "        # Add dropout and regularization\n",
    "        x = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        x = K.layers.Dropout(global_dropout_rate)(x)  # Apply dropout with 30% rate\n",
    "        x = K.layers.Dense(units=256, activation='relu', kernel_regularizer=K.regularizers.l2(global_l2_regularization))(x)  # Intermediate Dense layer with ReLU and L2 regularization\n",
    "        x = K.layers.Dropout(global_dropout_rate)(x)  # Apply dropout with 30% rate\n",
    "        model_output = K.layers.Dense(units=1, activation='linear', kernel_regularizer=K.regularizers.l2(global_l2_regularization))(x)  # Output layer with linear activation for regression\n",
    "    \n",
    "        # Create and compile the model\n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.AdamW(learning_rate=initial_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "    \n",
    "        return model\n",
    "\n",
    "elif architecture == 'ConvNeXT_linear_AdamW_Large':\n",
    "    architecture_preprocessing = K.applications.convnext.preprocess_input\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ConvNeXtLarge(include_top=False, weights=\"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(model_output)\n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=K.optimizers.AdamW(learning_rate=initial_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "elif architecture == 'ConvNeXt_Tiny_AdamW':\n",
    "    architecture_preprocessing = K.applications.convnext.preprocess_input\n",
    "\n",
    "    def get_compiled_model():\n",
    "        model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "        conv_base = K.applications.ConvNeXtTiny(include_top=False, weights=\"imagenet\", input_tensor=model_input)\n",
    "        model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "        model_output = K.layers.Dense(units=1, activation='linear')(model_output)\n",
    "    \n",
    "        # Learning rate schedule\n",
    "        initial_learning_rate = 1e-5\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "            initial_learning_rate=initial_learning_rate,\n",
    "            decay_steps=10000,\n",
    "            alpha=0.0\n",
    "        )\n",
    "        optimizer = K.optimizers.AdamW(learning_rate=lr_schedule, clipnorm=1.0)\n",
    "        model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "                        \n",
    "else:\n",
    "    print('!!!TYPO in architecture name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08cafa9e-bbe1-4d4b-a640-db0f76cd6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expt 1: Train on 5 sites, evaluate on 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dbe2fe91-089a-4e0b-8027-bb25354540a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, '1', '2', '3', '4', 'New_Sensor_1_Montreal_Atwater_August_2023', 'New_Sensor_1_Montreal_Jean_Talon_West_June_2023']\n",
      "Counts for each site ID:\n",
      "site_id\n",
      "NaN                                                167163\n",
      "4                                                   72476\n",
      "3                                                   58919\n",
      "2                                                   37500\n",
      "1                                                   31019\n",
      "New_Sensor_1_Montreal_Jean_Talon_West_June_2023     20956\n",
      "New_Sensor_1_Montreal_Atwater_August_2023            2277\n",
      "Name: count, dtype: int64\n",
      "Total Count: 390310\n"
     ]
    }
   ],
   "source": [
    "# How much data in each site\n",
    "unique_values_list = metadata['site_id'].unique().tolist()\n",
    "print(unique_values_list)\n",
    "\n",
    "# Get the count of each unique value\n",
    "site_id_counts = metadata['site_id'].value_counts(dropna=False)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts for each site ID:\")\n",
    "print(site_id_counts)\n",
    "\n",
    "# Total count\n",
    "print(\"Total Count:\", site_id_counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e4b77ec-2f72-4259-a521-29a8a270e5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sites:  [nan, '1', '2', '3', '4']\n",
      "validation_site:  New_Sensor_1_Montreal_Jean_Talon_West_June_2023\n",
      "test_site:  New_Sensor_1_Montreal_Atwater_August_2023\n",
      "Total training data count: 367077\n",
      "Total validation data count: 20956\n",
      "Total test data count: 2277\n"
     ]
    }
   ],
   "source": [
    "# Define the sites for training, validation, and testing\n",
    "\n",
    "validation_site = 'New_Sensor_1_Montreal_Jean_Talon_West_June_2023'\n",
    "test_site = 'New_Sensor_1_Montreal_Atwater_August_2023'\n",
    "\n",
    "# train sites = metadata - (test_sites) - (validation_sites)\n",
    "train_sites = metadata['site_id'].unique().tolist()\n",
    "train_sites.remove(test_site)\n",
    "train_sites.remove(validation_site)\n",
    "\n",
    "# Get the total count for each dataset\n",
    "train_data_count = metadata[metadata['site_id'].isin(train_sites)].shape[0]\n",
    "validation_data_count = metadata[metadata['site_id'] == validation_site].shape[0]\n",
    "test_data_count = metadata[metadata['site_id'] == test_site].shape[0]\n",
    "\n",
    "print('train_sites: ', train_sites)\n",
    "print('validation_site: ', validation_site)\n",
    "print('test_site: ', test_site)\n",
    "\n",
    "print(f\"Total training data count: {train_data_count}\")\n",
    "print(f\"Total validation data count: {validation_data_count}\")\n",
    "print(f\"Total test data count: {test_data_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "56823e49-1cf9-4026-a6a4-3d31639376fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a slice of the DataFrame to inspect\n",
    "# print(metadata[['site_id', 'image_path']].head())\n",
    "# print(metadata['site_id'].isin(train_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c001b37-cddb-4b49-ba75-6b620359a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/scott/Dropbox/IMAGINE Project/MSSI_Project\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ? ln_ufp_num_10s_ma_image_label_raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 367077 validated image filenames.\n",
      "Found 20956 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Select Exposure to be modelled\n",
    "import os\n",
    "import keras as K\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "def check_input_and_target_compatibility(target):\n",
    "    if ((target == 'ln_noise_10s_ma_image_label_raw' or \n",
    "         target == 'ln_ufp_num_10s_ma_image_label_raw' or\n",
    "         target == 'ln_ufp_size_10s_ma_image_label_raw') and\n",
    "        file == 'audio_path'):\n",
    "        print(\"!!! Input file not compatible with exposure !!!\")\n",
    "        return False\n",
    "        \n",
    "    elif ((target == 'ln_noise_10s_ma_spec_label_raw' or \n",
    "           target == 'ln_ufp_num_10s_ma_spec_label_raw' or\n",
    "           target == 'ln_ufp_size_10s_ma_spec_label_raw') and\n",
    "          file == 'image_path'):\n",
    "        print(\"!!! Input file not compatible with exposure !!!\")\n",
    "        return False\n",
    "        \n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# Get train and validate generators\n",
    "def get_train_val_generator(target):\n",
    "    # Making sure that wrong input is not fed into target\n",
    "    if not check_input_and_target_compatibility(target):\n",
    "        print(\"Please make sure `target` is compatible with `file_path`\")\n",
    "        return\n",
    "        \n",
    "    # Define the ImageDataGenerator with preprocessing function\n",
    "    generator = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing, \n",
    "                                                         horizontal_flip=True,\n",
    "                                                         vertical_flip=False)\n",
    "\n",
    "    # Training generator - use all sites except the validation and test sites\n",
    "    train_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['site_id'].isin(train_sites), [target, file]].reset_index(drop=True),  \n",
    "                                                    x_col=file,  # file = image_path or audio_path\n",
    "                                                    y_col=target,  # target = exposure to be modelled\n",
    "                                                    class_mode='raw', \n",
    "                                                    target_size=(256, 256),  # all of our images will be resized to 256 x 256\n",
    "                                                    color_mode='rgb', \n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    # Validation generator - use only the validation site\n",
    "    validate_generator = generator.flow_from_dataframe(dataframe=metadata.loc[metadata['site_id'] == validation_site, [target, file]].reset_index(drop=True),\n",
    "                                                       x_col=file,\n",
    "                                                       y_col=target,\n",
    "                                                       class_mode='raw',\n",
    "                                                       target_size=(256, 256),\n",
    "                                                       color_mode='rgb',\n",
    "                                                       batch_size=64,\n",
    "                                                       shuffle=False)\n",
    "\n",
    "    # Define callbacks\n",
    "    # Log file name (Change this if running multiple experiments on same model)\n",
    "    csv_logger = K.callbacks.CSVLogger(f'./rishabh_model_files/logs/XGB_experiment_1/{target},{architecture},{file},{meta_data_name}_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_{global_dropout_rate}_l2_{global_l2_regularization}.csv')\n",
    "    # csv_logger = K.callbacks.CSVLogger('./rishabh_model_files/logs/XGB_experiment_1/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.csv')    \n",
    "    # Model file name (Change this if running multiple experiments on same model)\n",
    "    # model_checkpoint = K.callbacks.ModelCheckpoint('./rishabh_model_files/models/XGB_experiment_1/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf', monitor='val_loss', mode='auto', save_weights_only=False,save_best_only=True)\n",
    "    model_checkpoint = K.callbacks.ModelCheckpoint(\n",
    "        f'./rishabh_model_files/models/XGB_experiment_1/{target},{architecture},{file},{meta_data_name}_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_{global_dropout_rate}_l2_{global_l2_regularization}.tf',\n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True\n",
    "    )\n",
    "    reduce_lr_on_plateau = K.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, mode='auto', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1)\n",
    "\n",
    "    return train_generator, validate_generator, [csv_logger, model_checkpoint, reduce_lr_on_plateau, early_stopping]\n",
    "\n",
    "target = input(\"What do you want to model: ln_noise_10s_ma_spec_label_raw, ln_noise_10s_ma_image_label_raw, ln_ufp_num_10s_ma_spec_label_raw, ln_ufp_num_10s_ma_image_label_raw, ln_ufp_size_10s_ma_image_label_raw, ln_ufp_size_10s_ma_spec_label_raw ?\")                  \n",
    "\n",
    "if target == 'ln_noise_10s_ma_image_label_raw':\n",
    "    train_generator, validate_generator, callbacks = get_train_val_generator(target)\n",
    "\n",
    "elif target == 'ln_noise_10s_ma_spec_label_raw':\n",
    "    train_generator, validate_generator, callbacks = get_train_val_generator(target)\n",
    "    \n",
    "elif target == 'ln_ufp_num_10s_ma_image_label_raw':\n",
    "    train_generator, validate_generator, callbacks = get_train_val_generator(target)\n",
    "\n",
    "elif target == 'ln_ufp_num_10s_ma_spec_label_raw':\n",
    "    train_generator, validate_generator, callbacks = get_train_val_generator(target)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_image_label_raw':\n",
    "    train_generator, validate_generator, callbacks = get_train_val_generator(target)\n",
    "    \n",
    "elif target == 'ln_ufp_size_10s_ma_spec_label_raw':\n",
    "    train_generator, validate_generator, callbacks = get_train_val_generator(target)\n",
    "    \n",
    "else:\n",
    "    print('!!!TYPO in exposure name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33a14d02-dda0-4c3e-8888-4623d53726ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from keras.preprocessing.image import load_img\n",
    "\n",
    "# # Assuming 'metadata' is your dataframe and 'file' is the column with image paths\n",
    "\n",
    "# # Filter the dataframe for site_id = 1\n",
    "# site_2_data = metadata[metadata['site_id'] == 'New_Sensor_1_Montreal_Atwater_August_2023']  # Ensure that '2' is the correct type (str or int)\n",
    "\n",
    "# # Select the first 5 entries; adjust as needed if you need random or more samples\n",
    "# sample_data = site_2_data.head(5)\n",
    "\n",
    "# # Plotting\n",
    "# fig, axes = plt.subplots(1, 5, figsize=(20, 4))  # Adjust the size as needed\n",
    "# for ax, idx in zip(axes, sample_data.index):\n",
    "#     img_path = sample_data.loc[idx, file]\n",
    "#     img = load_img(img_path, target_size=(256, 256))  # Ensure the target size matches your needs\n",
    "#     ax.imshow(img)\n",
    "#     ax.axis('off')\n",
    "#     ax.set_title(f'Site ID: 2\\n{img_path}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bbd4529-537f-4880-a0a9-e8889d7b28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch from the validate generator\n",
    "# x_val_batch, y_val_batch = next(validate_generator)\n",
    "\n",
    "# # Print the shape of the batch\n",
    "# print(f\"x_val_batch shape: {x_val_batch.shape}, y_val_batch shape: {y_val_batch.shape}\")\n",
    "\n",
    "# # Print and visualize some samples from the batch\n",
    "# num_samples_to_display = 5  # Number of samples to display\n",
    "\n",
    "# for i in range(num_samples_to_display):\n",
    "#     plt.imshow(x_val_batch[i].astype('uint8'))  # Convert to uint8 if necessary\n",
    "#     plt.title(f\"Label: {y_val_batch[i]}\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75aa593-83aa-49c1-a371-7f6aa961e0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "# Check a batch from the train generator\n",
    "# x_batch, y_batch = next(train_generator)\n",
    "# print(np.isnan(x_batch).any(), np.isnan(y_batch).any())\n",
    "\n",
    "# # Check a batch from the validate generator\n",
    "# x_batch, y_batch = next(validate_generator)\n",
    "# print(np.isnan(x_batch).any(), np.isnan(y_batch).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd5ce605-af4c-4578-b8a8-7778294a9856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 14:09:02.257305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11164 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2024-07-09 14:09:02.257908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11409 MB memory:  -> device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:06:00.0, compute capability: 6.1\n",
      "2024-07-09 14:09:02.258382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11409 MB memory:  -> device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "2024-07-09 14:09:02.258859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 11410 MB memory:  -> device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:0a:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "INFO:tensorflow:Collective all_reduce tensors: 346 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Collective all_reduce tensors: 346 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 14:12:46.325511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-09 14:12:46.950631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-09 14:12:47.366058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-09 14:12:47.671792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-09 14:12:48.145790: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8cd44eed30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-09 14:12:48.145835: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-07-09 14:12:48.145847: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-07-09 14:12:48.145855: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-07-09 14:12:48.145863: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2024-07-09 14:12:48.752273: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-07-09 14:12:55.289565: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-09 14:12:55.290266: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-09 14:12:55.326007: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_3_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-09 14:12:55.350352: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_2_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-09 14:12:59.941589: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5736/5736 [==============================] - ETA: 0s - loss: 0.3825 - mae: 0.3136INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/XGB_experiment_1/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base_L2_Dropout,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/XGB_experiment_1/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base_L2_Dropout,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5736/5736 [==============================] - 5519s 918ms/step - loss: 0.3825 - mae: 0.3136 - val_loss: 0.3580 - val_mae: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "5736/5736 [==============================] - ETA: 0s - loss: 0.1560 - mae: 0.2597INFO:tensorflow:Assets written to: ./rishabh_model_files/models/XGB_experiment_1/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base_L2_Dropout,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/XGB_experiment_1/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base_L2_Dropout,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5736/5736 [==============================] - 5268s 918ms/step - loss: 0.1560 - mae: 0.2597 - val_loss: 0.2868 - val_mae: 0.4252 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "5736/5736 [==============================] - ETA: 0s - loss: 0.1084 - mae: 0.2391INFO:tensorflow:Assets written to: ./rishabh_model_files/models/XGB_experiment_1/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base_L2_Dropout,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/XGB_experiment_1/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base_L2_Dropout,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5736/5736 [==============================] - 5280s 920ms/step - loss: 0.1084 - mae: 0.2391 - val_loss: 0.2715 - val_mae: 0.4228 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "5736/5736 [==============================] - ETA: 0s - loss: 0.0906 - mae: 0.2248INFO:tensorflow:Assets written to: ./rishabh_model_files/models/XGB_experiment_1/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base_L2_Dropout,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./rishabh_model_files/models/XGB_experiment_1/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base_L2_Dropout,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5736/5736 [==============================] - 5277s 920ms/step - loss: 0.0906 - mae: 0.2248 - val_loss: 0.2523 - val_mae: 0.4061 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "5736/5736 [==============================] - 5230s 912ms/step - loss: 0.0804 - mae: 0.2127 - val_loss: 0.2666 - val_mae: 0.4210 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "5736/5736 [==============================] - ETA: 0s - loss: 0.0725 - mae: 0.2023\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "5736/5736 [==============================] - 5219s 910ms/step - loss: 0.0725 - mae: 0.2023 - val_loss: 0.2557 - val_mae: 0.4099 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "5736/5736 [==============================] - 5235s 912ms/step - loss: 0.0570 - mae: 0.1798 - val_loss: 0.2752 - val_mae: 0.4266 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "5736/5736 [==============================] - ETA: 0s - loss: 0.0524 - mae: 0.1733\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "5736/5736 [==============================] - 5242s 914ms/step - loss: 0.0524 - mae: 0.1733 - val_loss: 0.2863 - val_mae: 0.4361 - lr: 1.0000e-05\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9300e435e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model = get_compiled_model()\n",
    "    \n",
    "\n",
    "#Fit Model\n",
    "model.fit(train_generator,\n",
    "          validation_data=validate_generator,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=int(np.ceil(train_generator.samples/train_generator.batch_size)),\n",
    "          validation_steps=int(np.ceil(validate_generator.samples/validate_generator.batch_size)),\n",
    "          callbacks=callbacks\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b2d047f-3b3f-4031-9b9d-59231fb685d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  ln_ufp_num_10s_ma_image_label_raw\n",
      "architecture ConvNeXT_linear_AdamW_Base_L2_Dropout\n",
      "best_epoch: 5\n",
      "best_val_loss: 0.6708037853240967\n",
      "best_val_mae: 0.627985954284668\n"
     ]
    }
   ],
   "source": [
    "#Identify Best Epoch\n",
    "res = pd.read_csv(filepath_or_buffer='./rishabh_model_files/logs/XGB_experiment_1/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.5.csv')\n",
    "res = res.sort_values('val_loss', ascending=True).reset_index(drop=True)\n",
    "best_epoch = res.epoch[0]\n",
    "best_val_loss = res.val_loss[0]\n",
    "best_val_mae = res.val_mae[0]\n",
    "print(\"target: \", target)\n",
    "print(\"architecture\", architecture)\n",
    "print(\"best_epoch:\", best_epoch)\n",
    "print(\"best_val_loss:\", best_val_loss)\n",
    "print(\"best_val_mae:\", best_val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52e231a4-20ef-4490-a214-5fc2f19c4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test code with ResNet50 and CIFAR10 dataset\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers, models\n",
    "# from tensorflow.keras.applications import ResNet50\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Load CIFAR-10 dataset\n",
    "# metad = keras.datasets.cifar10.load_data()\n",
    "# (x_train, y_train), (x_test, y_test) = metad\n",
    "# print(x_train)\n",
    "\n",
    "# # Normalize the data\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# # Convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, 10)\n",
    "# y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# # Data augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=False,\n",
    "#     samplewise_center=False,\n",
    "#     featurewise_std_normalization=False,\n",
    "#     samplewise_std_normalization=False,\n",
    "#     zca_whitening=False,\n",
    "#     rotation_range=15,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=False\n",
    "# )\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# def create_resnet50_model():\n",
    "#     model_input = K.layers.Input(shape=(256, 256, 3), dtype='float32', name='input')\n",
    "#     conv_base = K.applications.ResNet50(include_top=False, weights= \"imagenet\", input_tensor=model_input)\n",
    "#     model_output = K.layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "#     model_output = K.layers.Dense(units= 1, activation='linear')(model_output) \n",
    "#     model = K.models.Model(inputs=model_input, outputs=model_output)\n",
    "#     model.compile(\n",
    "#         optimizer=K.optimizers.Nadam(learning_rate = initial_learning_rate),\n",
    "#         loss = 'mse',\n",
    "#         metrics = ['mae']\n",
    "#     )\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# model = create_resnet50_model()\n",
    "\n",
    "# # Define callbacks\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"resnet50_cifar10.h5\", save_best_only=True),\n",
    "#     keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1),\n",
    "#     keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# ]\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
    "#           validation_data=(x_test, y_test),\n",
    "#           epochs=50,\n",
    "#           callbacks=callbacks)\n",
    "\n",
    "# # Evaluate the model\n",
    "# test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "# print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24818264-c0ba-4bc3-97cb-1f70f44e5299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# file = 'image_path'\n",
    "file = 'audio_path'\n",
    "\n",
    "# target = 'ln_noise_10s_ma_image_label_raw'\n",
    "# target = 'ln_noise_10s_ma_spec_label_raw'   \n",
    "# target = 'ln_ufp_num_10s_ma_image_label_raw'\n",
    "# target = 'ln_ufp_num_10s_ma_spec_label_raw'   \n",
    "# target = 'ln_ufp_size_10s_ma_image_label_raw'  \n",
    "target = 'ln_ufp_size_10s_ma_spec_label_raw'\n",
    "\n",
    "data = pd.read_csv(filepath_or_buffer='./rishabh_model_files/logs/XGB_experiment_1/'+target+','+architecture+','+file+','+meta_data_name+'_Combined_IMAGINE_goproUFP_V2_V3_04252024_XGB_expt_1_dropout_0.3.csv')\n",
    "\n",
    "# Extract data from DataFrame\n",
    "epochs = data['epoch']\n",
    "train_loss = data['loss']\n",
    "val_loss = data['val_loss']\n",
    "\n",
    "# Plotting loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title(f'{target},{architecture}')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Set y-axis ticks to intervals of 0.01\n",
    "# plt.yticks(np.arange(min(train_loss.min(), val_loss.min()), max(train_loss.max(), val_loss.max()) + 0.1, 0.1))\n",
    "\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b604ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 390310 validated image filenames.\n",
      "Found 390310 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 23:44:05.204856: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.205121: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.205350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.205577: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.205801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.206018: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.206243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.206460: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.206677: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.206895: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.207113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.207330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.228584: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.228854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.229093: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.229330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.229556: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.229784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.230006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.230322: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.230552: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.230753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14269 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-06-22 23:44:05.231003: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.231203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14394 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-06-22 23:44:05.231416: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.231616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14394 MB memory:  -> device: 2, name: NVIDIA RTX A4000, pci bus id: 0000:4b:00.0, compute capability: 8.6\n",
      "2024-06-22 23:44:05.231809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 23:44:05.232007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14394 MB memory:  -> device: 3, name: NVIDIA RTX A4000, pci bus id: 0000:4c:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 23:44:16.821687: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:447] Loaded runtime CuDNN library: 8.2.1 but source was compiled with: 8.9.4.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-06-22 23:44:16.822846: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at conv_ops_impl.h:1199 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node model_1/convnext_base_stem/convnext_base_stem_conv/Conv2D defined at (most recent call last):\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_8709/2969985133.py\", line 73, in <module>\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n\nDNN library is not found.\n\t [[{{node model_1/convnext_base_stem/convnext_base_stem_conv/Conv2D}}]] [Op:__inference_predict_function_42217]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 73\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m######### - Generate Predictions for Best CNN Models - ##############\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Best model for log(ufp_num) based on images:  ln_ufp_num, image, convnext, raw\u001b[39;00m\n\u001b[1;32m     72\u001b[0m ln_ufp_num_convnext_image_raw_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrishabh_model_files/models/ln_ufp_num_10s_ma_image_label_raw,ConvNeXT_linear_AdamW_Base,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mln_ufp_num_convnext_image_raw_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mln_ufp_num_convnext_image_raw_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator_convnext_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_generator_convnext_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mtest_generator_convnext_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# TODO: change model after training\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Best model for log(ufp_num) based on audio: ln_ufp_num, audio, convnext, raw\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# ln_ufp_num_convnext_audio_raw_model = load_model('rishabh_model_files/models/ln_ufp_num_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf')\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# metadata['ln_ufp_num_convnext_audio_raw_prediction'] = ln_ufp_num_convnext_audio_raw_model.predict(x=test_generator_convnext_audio, \u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#                                                                                              steps=int(np.ceil(test_generator_convnext_audio.samples/test_generator_convnext_audio.batch_size)))\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Best model for log(ufp_size) based on images: ln_ufp_size, image, convnext, raw \u001b[39;00m\n\u001b[1;32m     81\u001b[0m ln_ufp_size_convnext_image_raw_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ConvNeXT_linear_AdamW_Base,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node model_1/convnext_base_stem/convnext_base_stem_conv/Conv2D defined at (most recent call last):\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_8709/2969985133.py\", line 73, in <module>\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n\n  File \"/home/scottweichenthal/anaconda3/envs/imagine-py3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n\nDNN library is not found.\n\t [[{{node model_1/convnext_base_stem/convnext_base_stem_conv/Conv2D}}]] [Op:__inference_predict_function_42217]"
     ]
    }
   ],
   "source": [
    "#Generate Predictions and Add to Database\n",
    "# Running on `tst` or the whole data ?\n",
    "\n",
    "#Define Preprocessing functions\n",
    "architecture_preprocessing_convnext = K.applications.convnext.preprocess_input\n",
    "\n",
    "#Define Test Generators\n",
    "\n",
    "generator_test_convnext = K.preprocessing.image.ImageDataGenerator(preprocessing_function=architecture_preprocessing_convnext, \n",
    "                                                     horizontal_flip=False,\n",
    "                                                     vertical_flip = False)\n",
    "\n",
    "test_generator_convnext_audio = generator_test_convnext.flow_from_dataframe(dataframe=metadata[['audio_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'audio_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "test_generator_convnext_image = generator_test_convnext.flow_from_dataframe(dataframe=metadata[['image_path']].reset_index(drop=True),\n",
    "                                                     x_col= 'image_path',\n",
    "                                                     class_mode= None,\n",
    "                                                     target_size=(256, 256),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=64,\n",
    "                                                     shuffle=False)\n",
    "\n",
    "                                                                       \n",
    "######### - Generate Predictions for Best CNN Models - ##############\n",
    "\n",
    "# Best model for log(ufp_num) based on images:  ln_ufp_num, image, convnext, raw\n",
    "ln_ufp_num_convnext_image_raw_model = load_model('rishabh_model_files/models/ln_ufp_num_10s_ma_image_label_raw,ConvNeXT_linear_AdamW_Base,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf')\n",
    "metadata['ln_ufp_num_convnext_image_raw_prediction'] = ln_ufp_num_convnext_image_raw_model.predict(x=test_generator_convnext_image, \n",
    "                                                                                           steps=int(np.ceil(test_generator_convnext_image.samples/test_generator_convnext_image.batch_size)))\n",
    "# TODO: change model after training\n",
    "# Best model for log(ufp_num) based on audio: ln_ufp_num, audio, convnext, raw\n",
    "# ln_ufp_num_convnext_audio_raw_model = load_model('rishabh_model_files/models/ln_ufp_num_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf')\n",
    "# metadata['ln_ufp_num_convnext_audio_raw_prediction'] = ln_ufp_num_convnext_audio_raw_model.predict(x=test_generator_convnext_audio, \n",
    "#                                                                                              steps=int(np.ceil(test_generator_convnext_audio.samples/test_generator_convnext_audio.batch_size)))\n",
    "# Best model for log(ufp_size) based on images: ln_ufp_size, image, convnext, raw \n",
    "ln_ufp_size_convnext_image_raw_model = load_model('rishabh_model_files/models/ln_ufp_size_10s_ma_image_label_raw,ConvNeXT_linear_AdamW_Base,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf')\n",
    "metadata['ln_ufp_size_convnext_image_raw_prediction'] = ln_ufp_size_convnext_image_raw_model.predict(x=test_generator_convnext_image, \n",
    "                                                                                             steps=int(np.ceil(test_generator_convnext_image.samples/test_generator_convnext_image.batch_size)))\n",
    "# Best model for log(ufp_size) based on audio: ln_ufp_size, audio, convnext, raw\n",
    "ln_ufp_size_convnext_audio_raw_model = load_model('rishabh_model_files/models/ln_ufp_size_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf')\n",
    "metadata['ln_ufp_size_convnext_audio_raw_prediction'] = ln_ufp_size_convnext_audio_raw_model.predict(x=test_generator_convnext_audio,\n",
    "                                                                                                     steps=int(np.ceil(test_generator_convnext_audio.samples/test_generator_convnext_audio.batch_size)))\n",
    "# Best model for log(noise) based on images: ln_noise, image, convnext, raw\n",
    "ln_noise_convnext_image_raw_model = load_model('rishabh_model_files/models/ln_noise_10s_ma_image_label_raw,ConvNeXT_linear_AdamW_Base,image_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf')\n",
    "metadata['ln_noise_convnext_image_raw_prediction'] = ln_noise_convnext_image_raw_model.predict(x=test_generator_convnext_image,\n",
    "                                                                                               steps=int(np.ceil(test_generator_convnext_image.samples/test_generator_convnext_image.batch_size)))\n",
    "# Best model for log(noise) based on audio: ln_noise, audio, convnext, raw\n",
    "ln_noise_convnext_audio_raw_model = load_model('rishabh_model_files/models/ln_noise_10s_ma_spec_label_raw,ConvNeXT_linear_AdamW_Base,audio_path,gp_v2_v3_Training_Only_Combined_IMAGINE_goproUFP_V2_V3_04252024.tf')\n",
    "metadata['ln_noise_convnext_audio_raw_prediction'] = ln_noise_convnext_audio_raw_model.predict(x=test_generator_convnext_audio, \n",
    "                                                                                             steps=int(np.ceil(test_generator_convnext_audio.samples/test_generator_convnext_audio.batch_size)))               \n",
    "\n",
    "# Save dataframe with all predictions added\n",
    "metadata.to_csv(path_or_buf='compiled data/rishabh/metadata_gopro_training_only_UFP_V2_V3_04252024_predictions_added.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550689b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagine-env",
   "language": "python",
   "name": "imagine-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
